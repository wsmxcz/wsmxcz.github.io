[{"content":" 概述 # 图形处理单元（GPU）是当今人工智能发展的核心，其设计思路与中央处理单元（CPU）大相径庭。CPU 着眼于单线程性能，而 GPU 专为海量并行计算而生，能够同时执行数千条线程，从而高效完成深度学习模型训练和推理所需的大规模矩阵运算。\nGPU 的演化始于面向图形渲染的专用处理器。进入 1990 年代后，GPU 日益可编程化，并于 1999 年诞生了 NVIDIA 第一款真正意义上的 GPU。科学家们迅速将 GPU 在浮点计算上的优势应用于通用计算领域。2006 年，NVIDIA 推出了 CUDA（Compute Unified Device Architecture），这是业界首个面向 GPU 的完整通用编程平台。在 CUDA 问世之前，GPU 通常只能用于固定功能的图形流水线，而 CUDA 将 GPU 从专用图形加速器转变为通用计算引擎。更重要的是，NVIDIA 不仅在硬件架构上全面支持 CUDA，还在软件生态、开发者文档和工具链方面投入大量资源，从而牢牢锁定了开发者社区，形成了强大的生态护城河。\n尽管 GPU 计算能力在不断提升，但在深度学习场景下，“内存墙”依然是制约性能的关键瓶颈。以 NVIDIA H100 GPU 为例，其峰值浮点性能相较上代 A100 提升了超过 6 倍，然而内存带宽仅提升约 1.65 倍。这意味着，在大规模模型训练或推理时，越来越多的时间耗费在内存数据传输和访问上，而不仅仅是浮点运算本身。归一化（Normalization）与逐点（Pointwise）操作等内存吞吐量密集型操作，往往成为运行时的主要开销。因此，未来 AI 应用的发展既要在计算单元（如 Tensor Core）上做文章，也必须通过高带宽内存（HBM）以及算法级别的数据访问优化来降低内存瓶颈的影响。\n为了应对上述挑战，NVIDIA 构建了一个层次分明的 AI 软件栈，从底层的 GPU 硬件、驱动程序，到上层的深度学习框架，逐级协同优化性能。CUDA 平台本身就分为多个层次，包括低级并行编程模型（CUDA Driver API）、更易用的运行时 API、各类高性能库（如 cuDNN、cuBLAS）以及面向推理的 TensorRT。高层框架（如 PyTorch、TensorFlow、JAX）正是建立在这些组件之上，不断向上抽象，却能在底层硬件上直接利用最优实现。\n此外，NVIDIA 还提供 NGC 容器注册表，包含一系列预先优化并随时可用的 GPU 加速深度学习容器。这些容器将框架、库和驱动等组件打包在一起，经过严格测试以保证在支持的 GPU 上实现最佳性能，让用户无需费心处理复杂的依赖关系与环境配置。\n下文将逐层分析 NVIDIA 软件栈各关键组件：从并行计算基石 CUDA，到深度学习原语库 cuDNN，再到高层框架 PyTorch 及其 C++ 前端 LibTorch，最后介绍推理优化器 TensorRT 与 NGC 容器，并就兼容性、性能优化与部署给出建议。\nCUDA：并行计算的基石 # CUDA 简介 # CUDA（Compute Unified Device Architecture）是 NVIDIA 开创的一套通用并行计算平台与编程模型，旨在充分发挥 GPU 数千核的并行能力。它允许开发者使用包括 C、C++、Fortran、Python、Julia、MATLAB 等主流语言，通过少量关键字扩展将计算密集型代码段（Kernel）映射到 GPU 线程上并行执行，从而显著加速应用程序。\n与传统的图形流水线不同，CUDA 将 GPU 视为一个高度并行的计算引擎。程序员可以使用类似 C++ 的 CUDA 语言定义“CUDA Kernel”，每个 Kernel 在 GPU 上并行运行大量线程，从而并行完成矩阵乘法、卷积等深度学习核心运算。CUDA 平台也包含了完整的工具链，如编译器 nvcc、调试器 CUDA-GDB，以及 Nsight 系列性能分析工具，帮助开发者进行代码编译、调优和调试。\nCUDA 平台自推出以来就沿袭了一种“分层抽象”设计：在最底层，CUDA Driver API 提供对 GPU 硬件的细粒度控制；在上层，CUDA Runtime API 封装了常用操作，提升易用性；在更高层，还提供了诸如 cuBLAS、cuDNN、cuFFT 等高性能库，屏蔽了大多数繁杂的底层实现细节。不同需求的开发者可以根据实际场景选择合适层次的接口：系统级性能工程师或驱动开发者可直接使用 Driver API，而大多数应用开发者则偏好更为简洁的 Runtime API。\nCUDA 工具链与开发环境 # 1. nvcc 编译器\nnvcc 是 NVIDIA 官方提供的 CUDA 编译器，负责将包含 CUDA 关键字扩展的 C/C++ 代码编译成 GPU 可执行代码（包括 PTX 中间代码和最终 SASS 汇编）。 PTX（Parallel Thread Execution）是一种先行汇编语言，用作 NVIDIA GPU 的统一中间表示。尽管 PTX 保持一定的向后兼容性，但并未公开完整文档，因此在实际优化中仍有部分“黑箱”成分。SASS 则是针对具体 GPU 架构（如 Ampere、Hopper）的最终机器码。 2. CUDA Runtime API 与 Driver API\nCUDA Runtime API（如 libcudart.so）是一个更高层次的库，将驱动级 API 包装成更易用的函数接口。它管理 CUDA 上下文创建与销毁、内存分配与释放、内核启动等操作。对于绝大多数用户而言，Runtime API 能满足常见需求，但对于极端性能优化（如多 GPU 同步、流（Stream）并发管理），Driver API 仍不可或缺。 3. 调试与性能分析工具\nNsight 系列：包括 Nsight Systems（系统级性能分析）、Nsight Compute（核级性能分析）等，用于定位瓶颈、分析内存带宽与运算吞吐等。 CUDA-GDB：基于 GDB 的调试器，可在 GPU 上单步调试 CUDA Kernel。 CUDA MemCheck：内存错误检测工具，可帮助发现越界访问、未初始化内存读写等常见问题。 关键 CUDA 库 # CUDA 工具包内置了一系列针对不同场景的高性能 GPU 库，使得上层框架无需从头实现底层原语，即可直接调用经过高度调优的并行算法：\ncuBLAS：针对 GPU 优化的 BLAS（Basic Linear Algebra Subprograms），支持矩阵-矩阵、矩阵-向量等线性代数运算。 cuFFT：高性能快速傅里叶变换库，可对 1D、2D、3D 数据执行并行 FFT，并支持批量变换操作。 NCCL（NVIDIA Collective Communications Library）：多 GPU 通信库，提供 all-reduce、broadcast、reduce、all-gather 等集合通信操作，对分布式训练至关重要。 cuRAND：随机数生成库，支持多种分布、并行随机数生成。 NPP（NVIDIA Performance Primitives）：专注于图像与信号处理的 CUDA 加速库。 cuSPARSE：稀疏矩阵线性代数库，为稀疏矩阵乘法、求解等操作提供加速。 cuTENSOR：针对张量线性代数场景优化的库，提供高效的张量收缩与归约操作。 这些库不仅在 CUPTI 级别进行了深度优化，还因为融入 CUDA 生态后能与多种硬件特性（如 Tensor Core、张量融合等）协同工作，从而进一步拉高性能上限。\nNVIDIA GPU 驱动程序 # GPU 驱动程序是操作系统、GPU 硬件与 CUDA 工具包之间的桥梁，负责完成 GPU 初始化、内存管理、数据传输与内核调度等底层任务。驱动程序版本直接影响 CUDA 与高层深度学习框架（如 TensorFlow、PyTorch）之间的兼容性和性能。如果驱动过旧或与当前 CUDA 版本不匹配，常见后果包括：\n计算效率降低：驱动优化通常包含针对新 CUDA 版本和深度学习框架的性能补丁与内核优化。使用过旧驱动时，可能无法利用最新的硬件特性（例如 Tensor Core、FP8 计算、稀疏加速等），导致矩阵运算、卷积等核心操作速度下降。 兼容性问题：当深度学习框架升级到支持新 GPU 架构或 CUDA 版本后，旧驱动可能缺少必要接口或功能，导致运行时报错甚至无法启动。例如，PyTorch 包含的内置 CUDA 运行时可能要求驱动版本达到某一基线，否则会显示 “CUDA unavailable”。 稳定性与安全性：新驱动往往修复了先前版本中的 Bug，包括内存泄漏、死锁、崩溃等问题。停留在旧驱动可能频繁出现训练中断、系统崩溃，甚至存在已知安全漏洞。 新特性支持不足：以 NVIDIA Hopper 架构（H100）为例，它引入了全新的 Transformer Engine、FP8 精度支持与更高的 HBM3 带宽。只有更新到与之匹配的驱动版本（如 510 以上）后，才能充分利用这些特性。 为缓解驱动与 CUDA 版本不兼容带来的风险，NVIDIA 提供“CUDA 兼容性保证”机制，包括：\n向后兼容性：较新的驱动可向后兼容旧的 CUDA 版本，用户升级驱动后无需重装旧 CUDA。 向前兼容性：某些旧驱动也可兼容新 CUDA（通常为小版本差异），但存在性能或功能限制。例如，通过安装“cuda-compat-12-8”兼容包，用户可在驱动版本为 570 的系统上使用部分 CUDA 12.8 功能，但某些新特性仍受限。 尽管存在这些兼容措施，最佳实践仍是保持驱动与 CUDA、cuDNN、深度学习框架三者版本匹配。NVIDIA 官方维护了详细的兼容性矩阵（cuDNN 支持矩阵），在升级或部署时务必参考，以避免因版本不匹配引发的性能退化或运行错误。\ncuDNN：深度神经网络原语库 # cuDNN 简介 # cuDNN（CUDA Deep Neural Network Library）是 NVIDIA 专门针对深度神经网络核心运算而设计的 GPU 加速原语库。深度学习框架（PyTorch、TensorFlow、MXNet 等）通常会将诸如卷积（Convolution）、池化（Pooling）、归一化（Normalization）、激活（Activation）等常见操作委托给 cuDNN，以获得峰值性能优化。cuDNN 通过汇集多种算法实现并对其进行微调，使得在不同 GPU 架构下都能自动选择最优内核。\n与以往基于固定功能单元的深度学习例程不同，cuDNN 提供了可编程的接口并逐步引入“图” API，使用户能够以计算图（Graph）的形式定义多个操作的融合模式，从而进一步减少内存访问与内核启动开销。\n主要功能与性能优化 # cuDNN 对以下几类操作进行了深度优化：\n卷积与互相关（Convolution \u0026amp; Correlation） 在 cuDNN 9.10.1 中，对 Blackwell 架构（RTX 50 系列）GPU 的可变序列长度与 FP16/BF16 精度卷积性能进行了大幅提升。支持批大小超过 2 Giga-elements 的张量，并对 ConvolutionFwd/ConvolutionBwdData 主循环进行了融合优化。 矩阵乘法（GEMM） 基于 cuBLASLt 引擎，对 FP16/BF16 类型矩阵乘法进行了增强，并支持在同一内核中进行 alpha、beta 缩放以及与 Bias、ReLU、GeLU 的尾部融合（Fused Operation）。 归一化（Normalization）、Softmax 与池化（Pooling） 在 cuDNN 9.10.1 版本中，新增对自适应层归一化（Adaptive Layer Normalization）的支持，为 Transformer 类模型提供更高性能。 逐点操作（Pointwise） 包含常见的算术、数学、关系和逻辑逐点操作；cuDNN 通过向量化和线程并行等技术显著提高了这些操作的吞吐量。 图（Graph）API 从 cuDNN v8 开始，用户可通过图 API 将多个操作串联成一个计算图，由 cuDNN 自动拆分并优化内核执行顺序，减少中间数据拷贝和内核启动延迟。 值得注意的是，自 cuDNN 9.9.0 起，NVIDIA 已停止对 Turing 架构（T4、RTX 20 系列）之前的 GPU（即 Maxwell、Pascal、Volta）提供新的功能更新，鼓励用户在 Volta 及更高架构上使用 cuDNN 9.10.1 及以上版本，以充分利用最新的硬件特性与性能优化。\nPyTorch：领先的深度学习框架 # 设计理念与 GPU 加速 # PyTorch 凭借其命令式（Eager Execution）编程模型、与 NumPy 类似的 Python API 以及对动态计算图的支持而在研究社区迅速流行。它以“研究者优先”为设计原则，强调易用性与灵活性，让开发者能够以最直观的方式定义模型、调试代码并迭代实验。\n在 GPU 加速方面，PyTorch 通过 torch.cuda 模块与 CUDA 驱动层无缝对接。当用户调用 tensor.cuda() 或将模型与张量的 device 参数设置为 GPU 时，PyTorch 自动将数据与计算调度到 GPU 上执行。底层具体调用由 PyTorch 自带的 CUDA 运行时和 cuDNN 库共同完成——PyTorch 二进制包一般会打包特定版本的 CUDA 运行时与 cuDNN，因此用户在大多数情况下无需自行配置 CUDA 环境，只需确保 GPU 驱动版本满足要求。\n与 cuDNN 的深度集成 # 当 PyTorch 检测到 cuDNN 可用时，大多数卷积、池化、归一化，以及某些矩阵运算都将调用 cuDNN 提供的高度优化内核。用户只要在代码中使用标准的高层 API，例如 torch.nn.Conv2d、torch.nn.LayerNorm 等，即可自动获得 cuDNN 优化带来的数倍性能加速。\n同时，PyTorch 允许用户对 cuDNN 行为进行细粒度控制，例如：\ntorch.backends.cudnn.allow_tf32：是否启用 TensorFloat-32（TF32）计算，以便在支持的 Ampere（A100）及以上架构中利用 Tensor Core 以更高吞吐量执行矩阵乘法和卷积。 torch.backends.cudnn.benchmark：是否在运行时自动基准测试不同算法以选择最优卷积实现（适用于输入尺寸固定或变化不大时）。 torch.backends.cudnn.deterministic：是否强制使用确定性算法，以便在需要可复现结果时确保相同输入下输出一致，但会牺牲部分性能。 生态系统与分布式训练 # PyTorch 拥有繁荣的生态系统，涵盖了计算机视觉、自然语言处理、图神经网络等多个领域：\nCaptum：用于模型可解释性分析的开源库。 TorchVision、TorchText、TorchAudio：针对视觉、文本、音频等场景的常用数据集与预训练模型包。 PyTorch Geometric：支持在图形结构数据（Graph）上进行深度学习的库。 skorch：使 PyTorch 与 scikit-learn API 兼容的第三方库，方便科研与工程在统一接口下切换。 在分布式训练方面，PyTorch 提供了 torch.distributed 后端，支持 NCCL、Gloo 等通信框架，可在多 GPU、多节点环境下高效并行训练。更高层的库如 PyTorch Lightning、DeepSpeed、FairScale 等进一步简化了分布式训练流水线与大模型优化。\nLibTorch：PyTorch 的 C++ 前端 # 设计目标与应用场景 # LibTorch（又称 PyTorch C++ Frontend）是 PyTorch 在 C++ 环境下的镜像接口，旨在解决以下场景中的需求：\n低延迟系统：当应用对每个推理请求的响应时间要求极高（例如游戏引擎中的强化学习），C++ 原生库相比 Python 解释器具有更低的调用开销。 高并发环境：Python 的全局解释锁（GIL）限制了多线程并发性能，而 C++ 环境下可充分利用多线程与多 GPU 并行。 现有 C++ 代码库集成：许多工业级后端服务或图形软件、嵌入式系统以 C++ 为主，LibTorch 允许开发者在无需切换语言的前提下，直接加载经过 TorchScript 导出的模型并进行推理。 LibTorch 尽可能保留了与 Python API 近乎一致的接口设计：在 C++ 中将 Python 的点号访问（.）替换为双冒号（::），并支持大多数张量操作、自动求导功能。\nLibTorch 与 GPU 加速 # 使用 LibTorch 进行 GPU 加速时，需要显式指定设备信息：\n在创建新张量时，可通过 torch::Tensor t = torch::zeros({batch_size, dim}, torch::TensorOptions().device(torch::kCUDA)); 将张量直接分配到 GPU。 对于从数据集中读取的张量，则需调用 .to(device) 方法将其移动到 GPU，例如： torch::Tensor images = batch.data.to(device); 在模型定义或加载后，需要将模型参数移动到 GPU： generator-\u0026gt;to(device); discriminator-\u0026gt;to(device); 只要 torch::Device device(torch::kCUDA) 被正确设置，后续张量和模型操作都会在 GPU 上执行。若张量已位于目标设备，.to() 调用仍会检查并避免重复拷贝。\nLibTorch 也支持动态检测 CUDA 可用性，让代码在 CPU 与 GPU 环境中都能灵活运行：\ntorch::Device device(torch::kCUDA); if (!torch::cuda::is_available()) { device = torch::Device(torch::kCPU); } 部署流程与常见挑战 # 模型导出：通常在 Python 中训练好 PyTorch 模型后，通过 TorchScript 将其序列化为 .pt 或 .torchscript 文件。过程包括： scripted_model = torch.jit.trace(model, sample_input) scripted_model.save(\u0026#34;model.pt\u0026#34;) CMake 集成：在 C++ 项目中使用 LibTorch 时，需配置 CMake，使其能正确找到 LibTorch 库路径。例如： find_package(Torch REQUIRED) target_link_libraries(your_app \u0026#34;${TORCH_LIBRARIES}\u0026#34;) 同时，需要在系统中安装与 LibTorch 匹配的 CUDA 运行时与驱动，否则会出现链接或运行时错误。 cuDNN 支持问题：部分用户在编译时发现 LibTorch 并未启用 cuDNN（即 USE_CUDNN=0），导致卷积等操作降级到非 cuDNN 实现。解决方法通常是设置环境变量： export CAFFE2_USE_CUDNN=1 并确保系统安装了正确版本的 cuDNN 库。 跨平台兼容性：在不同操作系统（如 Ubuntu、Windows）或不同编译器（如 GCC 13 vs GCC 14）下，CUDA 与 LibTorch 的兼容性问题也常见。很多时候需要指定 CUDA_HOST_COMPILER 指向兼容的 GCC 版本，或在 CMake 中手动设置 CMAKE_PREFIX_PATH。 尽管上述挑战存在，一旦正确配置好环境，LibTorch 可以在 C++ 端提供与 Python 前端相同的算子性能，并且在静态编译与调用开销上更具优势，是生产部署的理想选择。\n兼容性与安装注意事项 # GPU 架构与计算能力 # NVIDIA GPU 按照“计算能力”（Compute Capability）进行分类，不同架构支持不同的 CUDA 功能与指令集：\nMaxwell（计算能力 5.x）：如 GTX 9 系列，已被淘汰，最新 cuDNN 版本仅提供有限支持。 Pascal（计算能力 6.x）：如 GTX 10 系列、Tesla P100，支持 cuDNN 9.10.1，但不支持部分 Blackwell/Hopper 专用优化。 Volta（计算能力 7.x）：如 Tesla V100，引入了首代 Tensor Core，兼容 cuDNN 9.10.1 与 CUDA 12.x。 Ampere（计算能力 8.x）：如 A100，引入第二代 Tensor Core，支持 TF32、更高效的 BF16 运算。 Hopper（计算能力 9.x）：如 H100，新增 Transformer Engine、FP8 精度、HBM3 等关键特性。 Blackwell（计算能力 12.x）：如 RTX 50系 GPU。第二代 Transformer Engine、FP4 精度。 当硬件架构快速升级时，软件栈需要相应更新以发挥硬件潜能。例如，H100 相较 A100 在深度学习推理上可实现 30 倍加速（得益于 Transformer Engine），但前提是配套的 CUDA 12.9 与 cuDNN 9.10.1 支持该特性。若仍使用旧版 cuDNN 或驱动，H100 只能以更低效的方式进行计算，无法真正释放潜力。\nCUDA、cuDNN 与 PyTorch 兼容性矩阵 # 合理搭配 CUDA、cuDNN 与 PyTorch 版本对系统稳定性和性能至关重要。下面列举常见版本组合与建议：\nPyTorch 版本 CUDA 支持版本 推荐 cuDNN 版本 驱动最低要求 适配 GPU 架构 PyTorch 2.7.0 CUDA 12.8 cuDNN 9.10.1 Linux 驱动 ≥570.26 或 Windows 驱动 ≥570.65 支持 Blackwell（RTX 50 系列）、Ampere（A100）、Hopper（H100） PyTorch 2.6.x CUDA 12.6/12.7 cuDNN 9.9.x Linux 驱动 ≥515 或 Windows 驱动 ≥515 Ampere、部分 Volta PyTorch 2.5.x CUDA 11.8 cuDNN 9.8.x Linux 驱动 ≥510 或 Windows 驱动 ≥510 Volta、Ampere 当存在多个可用 CUDA 版本时，PyTorch 二进制一般会自带与之匹配的 CUDA 运行时，而不会调用系统级 CUDA。例如，pip install torch==2.7.0 --index-url https://download.pytorch.org/whl/cu128 会安装带有内嵌 CUDA 12.8 的 PyTorch，用户无需再单独安装 CUDA Toolkit。 驱动更新应覆盖 PyTorch 所用的最低 CUDA 版本。例如，如果使用 PyTorch 内置的 CUDA 12.8，则驱动版本需不低于 570.26，以保证兼容。 在多架构环境中（如同时有 V100、A100、H100），建议统一使用支持所有 GPU 架构的最高版本 CUDA 与 cuDNN。例如，安装 cuDNN 9.10.1 与 CUDA 12.9，以便所有 GPU 都能获得最佳性能。 操作系统与编译器兼容性 # Ubuntu 24.04 与 GCC\nUbuntu 24.04 默认 GCC 版本为 13.2，但 CUDA 12.8 仅支持最高至 GCC 14。若系统中默认 GCC 版本过高或过低，都可能导致 nvcc 编译失败。可通过 apt install gcc-14 g++-14 并在 CMake 或编译时指定 -DCUDA_HOST_COMPILER=/usr/bin/gcc-14 来解决。 WSL2 与 Windows\n在 WSL2 环境下，需保证 Windows 端安装了支持 WSL2 的 NVIDIA 驱动（如 Windows NVIDIA Game Ready 或 Studio 驱动），并在 WSL2 中安装对应的 CUDA Toolkit 与 cuDNN 库。版本匹配规则与原生 Linux 类似。 macOS\n由于 Apple 自研芯片（M1/M2）不支持 NVIDIA CUDA，macOS 上无法执行 GPU 加速的 CUDA 应用。通常只能使用 CPU 版本，或通过外置 GPU（eGPU）与特定驱动进行有限支持。 高级优化与部署：TensorRT 与 NGC 容器 # TensorRT：高性能推理优化 # TensorRT 是 NVIDIA 专为高性能推理而设计的优化器与运行时库，支持将训练好的模型在生产环境中以最低延迟和最高吞吐量运行。TensorRT 可以将不同框架（如 PyTorch、TensorFlow）的模型导出为 ONNX 格式，并进行以下优化：\n算子融合（Layer \u0026amp; Tensor Fusion）\n将多个相邻的神经网络层或张量操作合并为一个高效 GPU 内核，减少内存拷贝与内核启动开销。 混合精度量化（INT8/FP16/FP8）\n利用低精度运算（如 INT8、FP16、FP8）显著降低计算与内存带宽需求，同时在误差可控范围内保持高精度。 内核选择与调优\n针对不同硬件架构与网络形状，TensorRT 会自动搜索最优内核实现，并将其编译入最优执行引擎。 动态张量形状支持\n能够处理可变批次大小或输入尺寸，通过动态张量维度与加速库（如 cuBLAS、cuDNN）的深度协同，保持高效运行。 TensorRT-LLM 与云端工具 # TensorRT-LLM：专门针对大型语言模型（LLM）的开源库，优化 Transformer 架构的 Attention、Layer Norm、FFN 等模块，使得在 NVIDIA GPU（尤其是 H100）上实现极限性能。 TensorRT Cloud：一项基于云的服务，根据用户指定的延迟与吞吐量需求，自动生成并交付最优推理引擎，加速部署流程。 主要框架集成：TensorRT 提供与 PyTorch 及 Hugging Face 等主流框架的深度集成，通过一行代码即可将模型转换为 TensorRT 引擎，有时可获得高达 6 倍的推理加速。 NVIDIA NGC 容器：简化软件栈与环境管理 # NGC（NVIDIA GPU Cloud）容器注册表汇集了工业级 GPU 加速容器，涵盖深度学习、机器学习、数据科学等多种场景。其优势包括：\n开箱即用的性能优化\nNGC 容器由 NVIDIA 官方维护，经过严格的性能工程调优，能够在各种支持的 GPU（从桌面级到数据中心级）上发挥最佳性能。 依赖管理与可移植性\n将操作系统库、CUDA、cuDNN、深度学习框架（如 PyTorch、TensorFlow、MXNet）、推理引擎（TensorRT）等打包在同一个容器中，用户无需担心“依赖地狱”。通过容器化，保证在本地、云端乃至边缘设备上都能获得一致结果。 持续更新与社区协作\nNVIDIA 工程师与开源社区每月发布新版本，根据最新硬件特性和性能优化进行更新。用户可及时获取对新架构（如 Hopper、Blackwell）的支持与补丁。 灵活的部署与扩展\n无论是在 Docker Engine、Kubernetes、Slurm 等环境中，NGC 容器都可无缝运行，并支持多种编排方式，使得从开发原型到大规模生产部署的流程更加顺畅。 常见 NGC 容器示例：\nTensorFlow Container：预装 TensorFlow 与 GPU 驱动、cuDNN、cuBLAS 等，适合深度学习训练与推理。 PyTorch Container：包含 PyTorch、TorchVision、CUDA、cuDNN、NCCL 等，支持分布式训练与混合精度。 TensorRT Container：主要用于推理任务，预装 TensorRT、ONNX Runtime、CUDA 与必要的依赖。 NGC AI Stack Metapackage：一站式容器，提供最新版本的所有 NVIDIA AI 相关库及工具。 示例：在WSL2/Ubuntu 24.04上为RTX 50系列构建稳定的GPU开发环境 # 本示例从零开始，详细演示在 Windows WSL2 环境中，如何在 Ubuntu 24.04 上安装并配置一套能够稳定支持 RTX 50 系列（Blackwell 架构）的 CUDA/C++ 开发环境。包括黑名单新驱动冲突、安装 NVIDIA 专有驱动、CUDA 12.8.1、cuDNN 9.10.1，以及关键的 CMake 配置要点。读者可严格按照以下步骤操作，以确保能够在 RTX 50 系列上进行 C++/CUDA 项目的编译与执行。\n1. Windows 侧准备 # 1.1 确保硬件虚拟化已启用 # 在 Windows 中打开 任务管理器 → 选择 “性能” 选项卡 → 在 “CPU” 信息区确认“虚拟化”已显示为 “已启用”。 若为“已禁用”，请重启机器并进入 BIOS/UEFI，将 Intel VT-x 或 AMD-V（视处理器而定）选项打开。 说明：WSL2 GPU 加速依赖底层的硬件虚拟化功能，务必先确认。\n1.2 更新 WSL2 内核 # 以管理员身份打开 PowerShell，执行： wsl.exe --update 等待更新完成后，再次重启 Windows，以确保最新的 WSL2 内核生效。 说明：最新的 WSL2 内核包含对 GPU 虚拟化（WDDM/DirectX）的优化，能够稳定地将底层 NVIDIA 驱动暴露给 WSL2 宿主。\n1.3 安装/更新 Windows NVIDIA 驱动程序 # 打开浏览器，访问 NVIDIA 官方驱动下载页（https://www.nvidia.com/Download/index.aspx），选择对应 RTX 50 系列（Blackwell 架构）及 Windows 系统的最新 “Game Ready” 或 “Studio” 驱动，版本号需≥ 570.00。 完成下载后，双击运行安装程序，并按照提示完成安装。完成后重启 Windows。 说明：WSL2 的 GPU 半虚拟化层依赖于 Windows 端的 NVIDIA 驱动。如果此驱动版本过旧或缺失，Ubuntu 端将无法检测到 GPU。\n2. WSL2 内 Ubuntu 24.04 安装与基础环境配置 # 2.1 安装 Ubuntu 24.04 # 以管理员身份打开 PowerShell，执行： wsl --install --distribution Ubuntu-24.04 等待系统自动下载并安装好 Ubuntu 24.04 后，系统会提示创建 Linux 用户、设置密码。根据提示完成初始设置。 如果已经安装过其他发行版，可使用： wsl --install -d Ubuntu-24.04 安装完成后，重启 Windows（可选，但推荐确保所有组件正常）。 2.2 禁用 Nouveau 驱动并安装 NVIDIA Linux 驱动 # 背景：Ubuntu 默认自带的开源 Nouveau 驱动与 NVIDIA 专有驱动冲突。必须先将 Nouveau 列入黑名单，再安装官方驱动，否则在后续 nvidia-smi 会出现 “未找到设备” 等错误。\n打开 Ubuntu 24.04 终端（可在 Windows 开始菜单搜索 “Ubuntu 24.04” 并启动），并切换到 root：\nsudo -i 在 /etc/modprobe.d/ 目录下创建一个黑名单文件，禁用 Nouveau：\necho \u0026#34;blacklist nouveau\u0026#34; \u0026gt; /etc/modprobe.d/blacklist-nouveau.conf echo \u0026#34;options nouveau modeset=0\u0026#34; \u0026gt;\u0026gt; /etc/modprobe.d/blacklist-nouveau.conf 更新 initramfs 并重启 WSL2：\nupdate-initramfs -u exit # 退出 root sudo reboot # 重启 Ubuntu（如果提示无效，可在 PowerShell 下 wsl --shutdown 后再重启 Ubuntu） 重启后，再次打开 Ubuntu 24.04 终端，切换到 root：\nsudo -i 手动安装 NVIDIA 官方专有驱动：\napt update apt install -y nvidia-driver-570-server-open 注意：nvidia-driver-570-server-open 中的 -open 后缀非常关键，若安装纯 nvidia-driver-570-server，在 Ubuntu 24.04 上会出现 “未找到设备” 的错误。\n安装完成后，直接执行 reboot 或在 PowerShell 下 wsl --shutdown，然后重新启动 Ubuntu 终端。\n重启并重新登录 Ubuntu 后，验证驱动是否就绪：\nnvidia-smi 如果输出中能看到 RTX 50 系列 GPU 型号、驱动版本（≥ 570.xx），则说明驱动安装成功。\n3. 安装 CUDA Toolkit 12.8.1 # 要点：WSL2 下需使用 NVIDIA 官方提供的“WSL-Ubuntu 专用” CUDA 安装包，避免安装过程中意外触发显示驱动部分并产生不兼容问题。\n切换到非 root 身份（如果当前已是 root，可直接继续）： exit 在用户目录下下载 NVIDIA CUDA 12.8.1 WSL-Ubuntu 专用 DEB 包： cd ~/Downloads wget https://developer.download.nvidia.com/compute/cuda/12.8.1/local_installers/cuda-repo-wsl-ubuntu-12-8-local_12.8.1-1_amd64.deb 添加 CUDA 仓库 Pin 配置并安装这个 DEB： sudo apt-key del 7fa2af80 # 如存在旧密钥可先删除 sudo mv cuda-repo-wsl-ubuntu-12-8-local_12.8.1-1_amd64.deb /tmp/ cd /tmp sudo dpkg -i cuda-repo-wsl-ubuntu-12-8-local_12.8.1-1_amd64.deb 将分发的 GPG Key 拷贝到 apt 密钥环： sudo cp /var/cuda-repo-wsl-ubuntu-12-8-local/cuda-*-keyring.gpg /usr/share/keyrings/ 更新 apt 软件源并安装 CUDA Toolkit： sudo apt-get update sudo apt-get -y install cuda-toolkit-12-8 验证 CUDA 安装： nvcc --version 如果输出中包含 Cuda compilation tools, release 12.8，则说明安装成功。 3.1 配置环境变量 # 为确保终端、CMake 等工具能正确找到 CUDA，可在用户的 ~/.bashrc 文件末尾追加以下两行并 source：\necho \u0026#39;export PATH=/usr/local/cuda-12.8/bin:$PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;export LD_LIBRARY_PATH=/usr/local/cuda-12.8/lib64:$LD_LIBRARY_PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 说明：不要忘记 source ~/.bashrc 或重启终端，否则新环境变量不会生效。\n4. 安装 cuDNN 9.10.1 # 要点：cuDNN 需要 NVIDIA 开发者账号才能下载，且要确保选择 “cuDNN 9.10.1 for CUDA 12.x” 与 Ubuntu 24.04 对应的 DEB 包。\n打开浏览器并登录 NVIDIA 开发者网站，进入 cuDNN 下载页面（https://developer.nvidia.com/cudnn-downloads）。\n选择以下选项并下载：\nPlatform: Linux Distribution: Ubuntu OS Version: 24.04 cuDNN SDK Version: 9.10.1 CUDA Version: 12.x File Format: deb (local) 架构: x86_64\n下载生成的文件名类似 cudnn-local-repo-ubuntu2404-9.10.1_1.0-1_amd64.deb。 将下载的 cuDNN DEB 包拷贝到 WSL2 下（可以放在 ~/Downloads）：\ncd ~/Downloads 安装 cuDNN 本地仓库：\nsudo dpkg -i cudnn-local-repo-ubuntu2404-9.10.1_1.0-1_amd64.deb 导入 cuDNN 仓库 GPG 密钥：\nsudo cp /var/cudnn-local-repo-ubuntu2404-9.10.1/cudnn-*-keyring.gpg /usr/share/keyrings/ 更新 apt 软件源并安装 cuDNN：\nsudo apt-get update sudo apt-get -y install libcudnn9 libcudnn9-dev （可选）验证 cuDNN 是否正确安装：\nsudo apt-get -y install libcudnn9-samples cd /usr/src/cudnn_samples_v9/mnistCUDNN make clean \u0026amp;\u0026amp; make ./mnistCUDNN 如果程序运行正常且输出正确的识别结果，则 cuDNN 安装无误。\n5. 安装 CMake（版本 3.20 及以上） # 要点：为了使用现代 CMake 配置 CUDA 项目，推荐至少安装 3.20 版本，否则需要手动编译或使用 Snap。\n默认 Ubuntu 24.04 仓库中的 CMake 版本已 ≥ 3.20，可直接安装： sudo apt-get install -y cmake 验证 CMake 版本： cmake --version 输出应类似 cmake version 3.20.x。若低于 3.20，可使用以下两种方式之一进行升级： Snap 安装（若可用）： sudo snap install cmake --classic 下载官方二进制包： 访问 https://cmake.org/download/ 并下载对应 Linux 二进制压缩包。 解压并将 bin/ 路径加入到 PATH 中，例如： tar -zxvf cmake-3.22.0-linux-x86_64.tar.gz sudo mv cmake-3.22.0-linux-x86_64 /opt/cmake-3.22 echo \u0026#39;export PATH=/opt/cmake-3.22/bin:$PATH\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc 再次检查： cmake --version 6. 示例 CMakeLists.txt 关键配置 # 以下示例展示了一个最简化的 CMake 配置要点，可用于 C++/CUDA 项目在 RTX 50 系列（Blackwell）、A100（Ampere）、H100（Hopper）等多架构 GPU 上同时编译。此处仅列出关键字段和注释，供读者在实际项目中直接参考或复制。\n# Minimum CMake version required cmake_minimum_required(VERSION 3.20) # Project 名称和启用语言 project(ExampleGPUProject LANGUAGES CXX CUDA) # --- C++ 标准设置 --- set(CMAKE_CXX_STANDARD 20) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_CXX_EXTENSIONS OFF) # --- CUDA Host Compiler 配置 --- # 强制让 nvcc 使用与 CXX 相同的主机编译器（避免 nvcc 随机选择不同版本） set(CMAKE_CUDA_HOST_COMPILER \u0026#34;${CMAKE_CXX_COMPILER}\u0026#34;) # 禁用将主机 C++ 编译器标志传播到 nvcc（有助于避免某些编译冲突） set(CUDA_PROPAGATE_HOST_FLAGS OFF) # --- CUDA 架构配置（多 GPU 支持） --- # 80: Ampere (A100) # 86: Ampere (部分 RTX 30/40 系列，与 A100 兼容) # 90: Hopper (H100) # 100: Blackwell (RTX 50 系列，假定计算能力 10.0) set(CMAKE_CUDA_ARCHITECTURES \u0026#34;80;86;90;100\u0026#34;) # --- 查找 LibTorch（如果需要 PyTorch C++ 接口，可选） --- # set(CMAKE_PREFIX_PATH \u0026#34;/home/youruser/libtorch/share/cmake/Torch\u0026#34;) # find_package(Torch REQUIRED) # if(Torch_FOUND) # message(STATUS \u0026#34;LibTorch found: ${TORCH_LIBRARIES}\u0026#34;) # endif() # --- 定义可执行文件及依赖示例 --- # 假设 src/main.cpp 与 src/kernel.cu 存在 add_executable(my_cuda_app src/main.cpp src/kernel.cu) # 如果使用 cuDNN，需要显式链接 libcudnn.so find_library(CUDNN_LIB cudnn PATHS /usr/lib/x86_64-linux-gnu) target_link_libraries(my_cuda_app PRIVATE ${CUDNN_LIB}) # 如果使用 LibTorch C++ 接口，则 # target_link_libraries(my_cuda_app PRIVATE \u0026#34;${TORCH_LIBRARIES}\u0026#34;) # --- 包含目录示例 --- target_include_directories(my_cuda_app PUBLIC ${CMAKE_SOURCE_DIR}/include # 项目头文件目录 /usr/local/cuda-12.8/include # CUDA 头文件 /usr/include/x86_64-linux-gnu # cuDNN 头文件一般已在系统默认搜索路径 # ${TORCH_INCLUDE_DIRS} # 如果链接 LibTorch，这行可启用 ) # --- 编译选项示例（可选） --- # 如果需要额外的警告或优化标志，可在此处添加 if(CMAKE_CXX_COMPILER_ID MATCHES \u0026#34;GNU|Clang\u0026#34;) target_compile_options(my_cuda_app PRIVATE -Wall -Wextra -Wpedantic $\u0026lt;$\u0026lt;CONFIG:RELEASE\u0026gt;:-O3 -DNDEBUG\u0026gt; $\u0026lt;$\u0026lt;CONFIG:DEBUG\u0026gt;:-g -O0\u0026gt; ) elseif(MSVC) target_compile_options(my_cuda_app PRIVATE /W4 /EHsc $\u0026lt;$\u0026lt;CONFIG:RELEASE\u0026gt;:/O2 /DNDEBUG\u0026gt; $\u0026lt;$\u0026lt;CONFIG:DEBUG\u0026gt;:/Zi /Od\u0026gt; ) endif() 说明：\nCMAKE_CUDA_HOST_COMPILER：避免 nvcc 随机挑选系统中其它 GCC 版本（例如 Ubuntu 24.04 还可能安装有 gcc-11、gcc-12），手动指定与 CMake CXX 编译器一致。 CUDA_PROPAGATE_HOST_FLAGS OFF：禁止将主机编译器的标志（如 -std=c++2a 等）通过 -Xcompiler 传递给 nvcc，从而避免与 nvcc 默认 flag 冲突。 CMAKE_CUDA_ARCHITECTURES：一次性列举所有目标 GPU 架构的 compute capability，比如 “80;86;90;100” 分别对应 A100、RTX 30/40、H100 与 RTX 50 系列。后续 nvcc 会生成针对这些架构的多组 PTX/SASS。 cuDNN 链接：如果项目中需要 cuDNN 库，可使用 find_library(CUDNN_LIB cudnn) 自动搜索系统路径下的 libcudnn.so，并在 target_link_libraries 中链接即可。 LibTorch（可选）：若要在同一项目中调用 PyTorch C++ 接口，需要先从 PyTorch 官网下载 LibTorch C++ 二进制包，并将 CMAKE_PREFIX_PATH 设置为解压后 libtorch/share/cmake/Torch 所在路径，然后 find_package(Torch REQUIRED)。 7. 完整验证流程 # 完成上述所有安装与配置后，可通过下面命令一一验证系统环境是否就绪并支持 RTX 50 系列 GPU：\nNVIDIA 驱动检查\nnvidia-smi 应显示你的 RTX 50 系列 GPU 型号，以及驱动版本 ≥ 570.xx。 如果输出中提示 “No devices were found” 或 “NVIDIA-SMI has failed”，请返回第 2 节检查驱动安装及 Nouveau 黑名单。 CUDA 工具链检查\nnvcc --version 输出应包含 Cuda compilation tools, release 12.8。 还可执行以下示例编译并运行： cat \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; \u0026gt; vector_add.cu #include \u0026lt;stdio.h\u0026gt; __global__ void vecAdd(const float* A, const float* B, float* C, int N) { int i = blockIdx.x * blockDim.x + threadIdx.x; if (i \u0026lt; N) C[i] = A[i] + B[i]; } int main() { int N = 1\u0026lt;\u0026lt;20; size_t size = N * sizeof(float); float *h_A = (float*)malloc(size), *h_B = (float*)malloc(size), *h_C = (float*)malloc(size); for(int i=0;i\u0026lt;N;i++){ h_A[i]=1.0f; h_B[i]=2.0f; } float *d_A, *d_B, *d_C; cudaMalloc(\u0026amp;d_A, size); cudaMalloc(\u0026amp;d_B, size); cudaMalloc(\u0026amp;d_C, size); cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice); cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice); vecAdd\u0026lt;\u0026lt;\u0026lt; (N+255)/256, 256 \u0026gt;\u0026gt;\u0026gt;(d_A,d_B,d_C,N); cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost); printf(\u0026#34;h_C[0]=%f\\\\n\u0026#34;, h_C[0]); // 预期输出 3.000000 cudaFree(d_A); cudaFree(d_B); cudaFree(d_C); free(h_A); free(h_B); free(h_C); return 0; } EOF nvcc vector_add.cu -o vector_add ./vector_add 如果看到 h_C[0]=3.000000，则说明 CUDA 能在 RTX 50 系列上正常执行。 cuDNN 检查（可选）\n# 前提：已安装 libcudnn9-samples cd /usr/src/cudnn_samples_v9/mnistCUDNN make clean \u0026amp;\u0026amp; make ./mnistCUDNN 正常运行并给出正确的识别结果，则 cuDNN 部分无误。 CMake+CUDA 构建示例项目\n在任意工作目录（如 ~/projects）下创建一个示例项目文件夹： mkdir -p ~/projects/ExampleCUDA \u0026amp;\u0026amp; cd ~/projects/ExampleCUDA 将前述的 CMakeLists.txt 关键配置内容保存为 CMakeLists.txt，并创建一个最简单的 src/main.cpp： // src/main.cpp #include \u0026lt;iostream\u0026gt; #include \u0026lt;cuda_runtime.h\u0026gt; __global__ void helloKernel() { printf(\u0026#34;Hello from GPU (thread %d)!\\\\n\u0026#34;, threadIdx.x); } int main() { helloKernel\u0026lt;\u0026lt;\u0026lt;1, 8\u0026gt;\u0026gt;\u0026gt;(); cudaDeviceSynchronize(); std::cout \u0026lt;\u0026lt; \u0026#34;CUDA 运行成功！\\\\n\u0026#34;; return 0; } 在项目根目录下执行： mkdir build \u0026amp;\u0026amp; cd build cmake .. make -j$(nproc) 最后运行： ./my_cuda_app 应该先打印若干条类似 Hello from GPU (thread 0)! … Hello from GPU (thread 7)!，然后打印 CUDA 运行成功！。这就证明 CMake 已正确调用 nvcc，将代码编译成可在 RTX 50 系列上执行的二进制。 8. 总结与常见问题： # “未找到设备”\n原因常见于：Windows 端 NVIDIA 驱动过旧／WSL2 未更新／Ubuntu 24.04 未安装 nvidia-driver-570-server-open 或 Nouveau 未黑名单。 解决：依次检查并重装 Windows 驱动 → wsl --update → Ubuntu 中黑名单 Nouveau → 安装 nvidia-driver-570-server-open → 重启 WSL2 → 再次验证 nvidia-smi。 nvcc 编译失败\n原因常见于：主机编译器版本与 CUDA 不兼容（例如 Ubuntu 上安装了过旧或过新的 GCC）。 解决：Ubuntu 24.04 默认 GCC 版本为 13.2，符合 CUDA 12.8 支持的范围（最多支持 GCC 14）。如果系统中意外存在其它版本，需通过 set(CMAKE_CUDA_HOST_COMPILER \u0026quot;${CMAKE_CXX_COMPILER}\u0026quot;) 或环境变量 export CUDAHOSTCXX=/usr/bin/g++-13 明确指定。 CMake 链接 cuDNN／LibTorch 失败\n确认 find_library(CUDNN_LIB cudnn) 能正确找到 /usr/lib/x86_64-linux-gnu/libcudnn.so；若返回空，可手动指定： find_library(CUDNN_LIB cudnn HINTS /usr/lib/x86_64-linux-gnu) 如果使用 LibTorch，请确保 CMAKE_PREFIX_PATH 指向 LibTorch 解压后 share/cmake/Torch 的完整路径，且链接时加上 ${TORCH_LIBRARIES}。 PyTorch（Python）与系统 CUDA 依赖冲突\nPyTorch 自带 CUDA 运行时，与系统级 CUDA Toolkit 解耦。只要系统驱动 ≥ 570 支持 CUDA 12.8，使用 pip3 install torch --index-url https://download.pytorch.org/whl/cu128 即可完成 Python 端 GPU 支持，无需担心与系统 CUDA Toolkit 版本匹配。 结论与建议 # 从整体来看，现代深度学习工作流依赖于 NVIDIA 从硬件到软件的完整生态系统：\nCUDA 提供了并行编程基础，抽象了底层 GPU 复杂性，同时保留对细粒度控制的支持。 cuDNN 作为深度神经网络运算的关键优化层，为框架提供了高度优化的卷积、归一化、矩阵乘法、注意力机制等操作。 PyTorch 通过其 Pythonic、命令式的 API，让研究者能够专注于算法创新，而将底层性能优化完全交给 CUDA 与 cuDNN。 LibTorch 则在 C++ 端保持与 Python 相近的易用性，同时满足对低延迟、高并发与无缝集成的苛刻生产需求。 TensorRT 将训练好的模型在推理环节进行深度优化，通过算子融合、混合精度量化等技术实现极致性能。 NGC 容器 则解决了“依赖地狱”与跨环境一致性问题，让用户能够专注于模型开发与部署，而无需为环境配置耗费大量精力。 然而，这一生态系统的强大在带来性能的同时，也伴随着复杂的版本依赖与兼容性挑战。以下建议可帮助用户更平滑地构建与维护 NVIDIA AI 平台环境：\n驱动程序版本控制 将 NVIDIA GPU 驱动程序保持在与所用 CUDA、cuDNN 版本兼容的范围。定期检查 NVIDIA 官方兼容性矩阵，并在升级 CUDA 或深度学习框架后同步升级驱动。 严格遵循兼容性矩阵 在安装或升级时务必参阅 NVIDIA 和 PyTorch 官方文档，确保 CUDA、cuDNN 与深度学习框架各自版本匹配，以免出现运行时错误或性能问题。 优先使用 NGC 容器 尤其是在团队协作或多环境部署场景下，优先选用 NGC 标准容器。这样可以省去手工配置过程、减少环境差异带来的调试成本，并及时享用 NVIDIA 官方的性能优化更新。 权衡 Python 与 C++ 部署 对于快速原型开发与研究实验，可优先使用 PyTorch Python 前端，享受其丰富的生态与灵活性；对于对延迟、资源占用要求极高的生产推理场景，则应考虑使用 LibTorch C++ 接口，将模型导出为 TorchScript 后嵌入 C++ 服务中。 关注硬件演进与内存带宽瓶颈 随着 GPU 架构不断更迭，仅提升算力不足以获得线性性能提升。针对大型模型的训练与推理，应关注算法层面的内存访问优化（如张量重排、Operator Fusion）以及硬件层面的带宽升级（如 HBM3），以缓解“内存墙”带来的瓶颈。 持续学习与跟进新特性 NVIDIA 不断在 CUDA、cuDNN、TensorRT 等软件栈中引入新功能（如 cuDNN 图 API、多级浮点混合精度、FP8 支持等）。及时了解这些新特性，并在合适场景下集成到流水线中，可在性能与资源效率上取得更大提升。 总体而言，要在复杂多变的深度学习生态中保持竞争力，不仅需要关注算法创新，也要在硬件与软件层面持续优化并保持敏锐。通过遵循兼容性最佳实践、利用容器化部署与版本管理，以及结合最新的硬件特性，开发者能够更高效地将研究成果推向生产，并在大模型时代中游刃有余。\n","date":"2025-06-06","externalUrl":null,"permalink":"/zh-cn/utilities/nvidia-cuda/test/","section":"Utilities","summary":"\u003ch2 class=\"relative group\"\u003e概述 \n    \u003cdiv id=\"%E6%A6%82%E8%BF%B0\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%A6%82%E8%BF%B0\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e图形处理单元（GPU）是当今人工智能发展的核心，其设计思路与中央处理单元（CPU）大相径庭。CPU 着眼于单线程性能，而 GPU 专为海量并行计算而生，能够同时执行数千条线程，从而高效完成深度学习模型训练和推理所需的大规模矩阵运算。\u003c/p\u003e","title":"基于 NVIDIA GPU 的深度学习生态环境搭建","type":"utilities"},{"content":" 匹配规则 # 在编辑Markdown时，特别是在页面渲染应用场景下，数学公式往往需要特定的转义定界符，这里我列出了一些常用定界符的正则表达式，以实现快速的批量匹配：\n行内公式 \\(...\\): (?\u0026lt;!\\\\)\\\\\\((.*?)(?\u0026lt;!\\\\)\\\\\\) \\\\(...\\\\): (?\u0026lt;!\\\\)\\\\\\\\\\((.*?)(?\u0026lt;!\\\\)\\\\\\\\\\) $...$: (?\u0026lt;!\\$)\\$(?!\\$)(.*?)(?\u0026lt;!\\$)\\$(?!\\$) 行间公式 \\[...\\]: (?\u0026lt;!\\\\)\\\\\\[\\n(.*?)\\n(?\u0026lt;!\\\\)\\\\\\] \\\\[...\\\\]: (?\u0026lt;!\\\\)\\\\\\\\\\[\\n(.*?)\\n(?\u0026lt;!\\\\)\\\\\\\\\\] $$...$$: (?\u0026lt;!\\$)\\$\\$(?!\\$)\\n(.*?)\\n(?\u0026lt;!\\$)\\$\\$(?!\\$) \\begin{equation}...\\end{equation} (?\u0026lt;!\\\\)\\\\begin{equation}\\n(.*?)\\n(?\u0026lt;!\\\\)\\\\end{equation} 这里使用负向回顾断言（(?\u0026lt;!\\\\)、(?\u0026lt;!\\$)）和负向前瞻断言（(?!\\\\\\$、(?!\\$）来避免分隔符之间的冲突（例如，$...$ 与 $$...$$）。对于行间公式，加入了换行符\\n，如果不需要可以删去。\n替换规则 # 匹配完成后常常需要替换，使用基本的逻辑即可，列出如下：\n\\(...\\): \\\\\\($1\\\\\\) \\\\(...\\\\): \\\\\\\\($1\\\\\\\\) $...$: $$$1$$ \\[...\\]: \\\\[\\n$\\n1\\\\] \\\\[...\\\\]: \\\\\\\\[\\n$1\\n\\\\\\\\] $$...$$: $$$$\\n$1\\n$$$$ \\begin{equation}...\\end{equation} \\begin{equation}\\n$1\\n\\end{equation} ","date":"2025-03-15","externalUrl":null,"permalink":"/zh-cn/utilities/unifying-multi-format-mathematical-formula-delimiters-via-regular-expressions/test/","section":"Utilities","summary":"\u003ch3 class=\"relative group\"\u003e匹配规则 \n    \u003cdiv id=\"%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%8C%B9%E9%85%8D%E8%A7%84%E5%88%99\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003cp\u003e在编辑Markdown时，特别是在页面渲染应用场景下，数学公式往往需要特定的转义定界符，这里我列出了一些常用定界符的正则表达式，以实现快速的批量匹配：\u003c/p\u003e","title":"基于正则表达式统一匹配替换多格式数学公式定界符","type":"utilities"},{"content":"","date":"2025-06-06","externalUrl":null,"permalink":"/zh-cn/tags/cuda/","section":"Tags","summary":"","title":"Cuda","type":"tags"},{"content":"","date":"2025-06-06","externalUrl":null,"permalink":"/zh-cn/tags/gpu/","section":"Tags","summary":"","title":"Gpu","type":"tags"},{"content":"","date":"2025-06-06","externalUrl":null,"permalink":"/zh-cn/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"2025-06-06","externalUrl":null,"permalink":"/zh-cn/utilities/","section":"Utilities","summary":"","title":"Utilities","type":"utilities"},{"content":"","date":"2025-06-06","externalUrl":null,"permalink":"/zh-cn/tags/utility/","section":"Tags","summary":"","title":"Utility","type":"tags"},{"content":"","date":"2025-06-06","externalUrl":null,"permalink":"/zh-cn/","section":"如我所见","summary":"","title":"如我所见","type":"page"},{"content":"My name is Zheng (Alex) Che. I earned a Bachelor\u0026rsquo;s degree from the Cuiying Honors College of Lanzhou University. I\u0026rsquo;m currently pursuing a Master\u0026rsquo;s degree at the University of Science and Technology of China.\nMy research interests center on employing neural networks, quantum computing, and other advanced computational methods to explore quantum many-body systems, particularly focusing on the structure and properties of electronic systems.\nIn addition, I have a keen interest in fundamental and cutting-edge topics in mathematics, physics, and computer science.\n","date":"2025-03-19","externalUrl":null,"permalink":"/zh-cn/aboutme/","section":"如我所见","summary":"\u003cp\u003eMy name is Zheng (Alex) Che. I earned a Bachelor\u0026rsquo;s degree from the Cuiying Honors College of Lanzhou University. I\u0026rsquo;m currently pursuing a Master\u0026rsquo;s degree at the University of Science and Technology of China.\u003c/p\u003e","title":"关于我","type":"page"},{"content":"","date":"2025-03-17","externalUrl":null,"permalink":"/zh-cn/series/determinant-based-quantum-chemistry/","section":"Series","summary":"","title":"Determinant-Based Quantum Chemistry","type":"series"},{"content":"","date":"2025-03-17","externalUrl":null,"permalink":"/zh-cn/docs/","section":"Docs","summary":"","title":"Docs","type":"docs"},{"content":"","date":"2025-03-17","externalUrl":null,"permalink":"/zh-cn/series/group-theory/","section":"Series","summary":"","title":"Group Theory","type":"series"},{"content":" 概述 # 对于无结构的搜索问题，Grover 算法相较于经典算法从理论上提供了平方根级别的加速。\n无结构搜索问题 # 无结构搜索问题可以形式化为：\n经典搜索问题：\nInput: 问题的规模 \\(n \\in \\mathbb{N} \\)，一个能够执行函数 \\(f: \\{0,1\\}^n \\rightarrow \\{0,1\\}\\) 的 Oracle.\nOutput: 一个满足 \\(f(\\mathbf{x})=1\\) 的string \\(\\mathbf{x}\\).\n这个问题可以有一些变体，例如我们可以先验设定问题解的数量（不存在解，只有唯一解，存在多个解等）。\n限制函数的输入域为 \\(\\mathbb{Z}_{2^n}\\) 并不会缩小或特化问题适用的范围，但可以帮助我们简化问题。对于任意的 \\(N \\in \\mathbb{Z}_{2^n}\\) 和任意函数 \\(f: \\mathbb{Z}_N \\rightarrow \\{0, 1\\}\\)，我们可以将 \\(\\mathbb{Z}_N\\) 嵌入到 \\(\\mathbb{Z}_{2^n}\\,|\\, n = [\\log_2 N]\\) 中，并规定超出范围的输入返回0。\n很容易想象到，在经典计算机上求解此问题，在最坏的情形下，需要调用Oracle \\(2^n\\) 次（遍历整个问题空间，理论上界）。但量子计算机上执行的 Grover 算法能够提供平方根级的加速，将调用次数的理论上界减少至 \\(2^{n-1}\\)。\nGrover 算法 # 我们此处设定问题解的数量是有限的。Grover算法需要两个寄存器：寄存器1包含 \\(n\\) 个量子比特，用于存储数据信息；寄存器2包含一个量子比特，用以存储条件函数 \\(f(x)\\) 的值。首先将寄存器1中的量子比特制备至最大叠加态（利用 \\(H^{\\otimes n}\\)），寄存器2制备到 \\(\\ket{-}\\) 态。因此，整个系统初始处于量子态： $$ \\ket{\\Phi_0} = \\frac{1}{\\sqrt{N}} \\sum_{\\mathbf{x}\\in \\{0,1\\}^n} \\ket{\\mathbf{x}} \\otimes \\ket{-} $$\nGrover算法使用一个酉算符 \\(U_f\\) 实现搜索算法中的函数 \\(f\\)，定义为： $$ U_f : \\mathcal{H}^n \\otimes \\mathcal{H}^1 \\rightarrow \\mathcal{H}^n \\otimes \\mathcal{H}^1 $$ $$ U_f \\ket{\\mathbf{x}}\\ket{y} = \\ket{\\mathbf{x}} \\ket{f(\\mathbf{x}) \\oplus y} = \\ket{\\mathbf{x}} X^{f(\\mathbf{x})} \\ket{y} $$\n基于此，我们可以定义无结构搜索问题的量子版本：\n量子搜索问题：\nInput: 问题的规模 \\(n \\in \\mathbb{N} \\)，一个能够实现上述 \\(U_f\\) 的 Oracle。 \\(M=|f^{-1}(1)|, M\u0026gt;0\\)\nOutput: 一个满足 \\(f(\\mathbf{x})=1\\) 的string \\(\\mathbf{x}\\).\n我们下面说明，不施加任何额外操作，直接测量寄存器1即可得到结果。寄存器1的量子态可以写为： $$ \\ket{s} = \\frac{1}{\\sqrt{N}} \\sum_{\\mathbf{x}\\in \\{0,1\\}^n} \\ket{\\mathbf{x}} $$\n我们设定： $$ \\ket{s_0} = \\frac{1}{\\sqrt{N}} \\sum_{\\mathbf{x}\\in \\{0,1\\}^n, f(\\mathbf{x})=0} \\ket{\\mathbf{x}} $$ $$ \\ket{s_1} = \\frac{1}{\\sqrt{N}} \\sum_{\\mathbf{x}\\in \\{0,1\\}^n, f(\\mathbf{x})=1} \\ket{\\mathbf{x}} $$ $$ \\theta = \\arcsin{\\sqrt{M/N}} $$\n那么我们可以将寄存器1的量子态写为： $$ \\ket{s} = \\sqrt{\\frac{N-M}{N}} \\ket{s_0} + \\sqrt{\\frac{M}{N}} \\ket{s_1} = \\cos{\\theta}\\ket{s_0} + \\sin{\\theta} \\ket{s_1} $$\n在 \\(\\mathcal{H}^n\\) 的计算基上测量 \\(\\ket{s}\\)，就可以得到获得满足 \\(f(\\mathbf{x})=1\\) 的 \\(\\mathbf{x}\\) 的概率： $$ p = \\sin^2{\\theta} = \\frac{M}{N} $$ 这代表了正确得到搜索问题解的概率，相比经典策略并没有提供任何优势。\n为了找出可能存在的量子优势，我们需要一种称为“振幅放大”的技术，这可以提高目标态 \\(\\ket{s_1}\\) 的振幅从而增大获得正确答案的概率。振幅放大操作需要利用一种称为 Grover 迭代器的酉算符 \\(G\\)，定义为： $$ G (\\cos{\\alpha}\\ket{s_0} + \\sin{\\alpha} \\ket{s_1}) = \\cos{(\\alpha+2\\theta)}\\ket{s_0} + \\sin{(\\alpha + 2 \\theta)} \\ket{s_1}, \\forall \\alpha \\in \\mathbb{R} $$\n对寄存器1施加 \\(k \\in \\mathbb{N_0}\\) 次Grover迭代器，就可以得到： $$ G^k \\ket{s} = \\cos{(2k+1)\\theta} \\ket{s_0} + \\sin{(2k+1)\\theta} \\ket{s_1} $$\n至此，我们可以描述出 Grover 算法的整个流程（只考虑寄存器1）。首先，我们制备出初始的最大叠加态 \\(\\ket{s}\\)，然后对 \\(\\ket{s}\\) 施加 \\(k\\) 次 Grover迭代器，最后在 \\(\\mathcal{H}^n\\) 的计算基上测量 \\(\\ket{s}\\) 得到结果。Grover迭代器的施加次数 \\(k\\) 取决于 \\(2(k+1)\\theta\\) 与 \\(\\pi/2\\) 的接近程度，这会让得到正确解的概率最大化。\nGrover搜索算法的量子线路示意图 自然的我们会提出几个问题：\nGrover 迭代器怎么具体实现？特别是我们在算法输入中只给定了一个实现 \\(U_f\\) 操作的 Oracal。 Grover 迭代器的最小次数是多少？我们自然希望量子线路越短越好。 量子方案相较于经典方案的优势在哪里？ 我们将在以下几节的内容中一一给出答案。\nGrover 迭代器 # 我们现在说明如何 Grover 迭代器的具体实现以及性质。Grover 迭代器的构建依赖于两个作用在 \\(\\mathcal{H}^n\\) 上的酉算符： $$ U_{\\omega} = I - 2\\ket{s_1}\\bra{s_1} $$ $$ U_s = 2\\ket{s}\\bra{s} - I $$\n其中，\\(U_{\\omega}\\) 作用于 \\(\\ket{s}\\) 会翻转 \\(\\ket{s_1}\\) 的振幅，而 \\(U_s\\) 作用于 \\(\\ket{s}\\) 会翻转整个 \\(\\mathcal{H}^n\\) 的振幅。我们可以证明，Grover 迭代器可以通过以下方式构建： $$ G = U_{\\omega} U_s $$\n容易验证，$U_\\omega$, $U_s$ 和 $G$ 都是酉算符。$U_\\omega$, $U_s$ 同时也是厄米算符。这些算符都具有明确的几何意义，我们进行简单的研究。定义一个由 $\\ket{s_0}$ 和 $\\ket{s_1}$ 张成的二维复平面 $\\mathcal{P}$： $$ P = \\mathbb{C} \\ket{s_0} + \\mathbb{C} \\ket{s_1} $$ 显然，$\\ket{s_0}$ 和 $\\ket{s_1}$ 是 $\\mathcal{P}$ 的一组正交基。$U_{\\omega}$ 的\n","date":"2025-03-17","externalUrl":null,"permalink":"/zh-cn/docs/quantum-algorithm/grover/","section":"Docs","summary":"\u003ch2 class=\"relative group\"\u003e概述 \n    \u003cdiv id=\"%E6%A6%82%E8%BF%B0\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%A6%82%E8%BF%B0\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e对于无结构的搜索问题，Grover 算法相较于经典算法从理论上提供了平方根级别的加速。\u003c/p\u003e","title":"Grover算法","type":"docs"},{"content":"","date":"2025-03-17","externalUrl":null,"permalink":"/zh-cn/series/quantum-algorithm/","section":"Series","summary":"","title":"Quantum Algorithm","type":"series"},{"content":"","date":"2025-03-17","externalUrl":null,"permalink":"/zh-cn/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":" 为什么要研究群表示论？ # 在第一节中，我们介绍了群的基本定义以及群理论中的一些基本概念，我们使用的数学语言是“抽象”的，这不利于群论的进一步应用。群表示论（更正式地，线性表示理论）就是为了解决这一问题，它可以帮助我们将抽象的群结构具体化到线性变换或矩阵上，使得我们能用线性代数、矩阵论等成熟的工具去分析群的性质。\n群的线性表示 # 定义: 设 \\(G\\) 是一个群，\\(V\\) 是域 \\(K\\) 上的一个向量空间，\\(V\\) 上所有可逆线性变换组成的乘法群记作 \\(\\mathrm{GL}(V)\\)。\\(G\\) 到 \\(\\mathrm{GL}(V)\\) 的一个群同态 \\(\\varphi\\) 称为 \\(G\\) 在域 \\(K\\) 上的一个线性表示（简称为 \\(K\\)-表示或者表示）。\\(V\\) 称为表示空间。若 \\(V\\) 是有限维的，则 \\(V\\) 的维数 \\(\\dim_K V\\) 称为表示的次数（或维数），记作 \\(\\deg \\varphi\\) ；若 \\(V\\) 是无限维的，则称 \\(\\varphi \\) 是 \\(G\\) 的无限维表示。\n","date":"2025-03-17","externalUrl":null,"permalink":"/zh-cn/docs/summary-of-group-theory/group2/","section":"Docs","summary":"\u003ch2 class=\"relative group\"\u003e为什么要研究群表示论？ \n    \u003cdiv id=\"%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%A0%94%E7%A9%B6%E7%BE%A4%E8%A1%A8%E7%A4%BA%E8%AE%BA\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E7%A0%94%E7%A9%B6%E7%BE%A4%E8%A1%A8%E7%A4%BA%E8%AE%BA\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e在第一节中，我们介绍了群的基本定义以及群理论中的一些基本概念，我们使用的数学语言是“抽象”的，这不利于群论的进一步应用。群表示论（更正式地，线性表示理论）就是为了解决这一问题，它可以帮助我们将抽象的群结构具体化到线性变换或矩阵上，使得我们能用线性代数、矩阵论等成熟的工具去分析群的性质。\u003c/p\u003e","title":"群论：群表示论","type":"docs"},{"content":" 概述 # 在现代量子化学中，行列式驱动的方法，如 Hartree-Fock (HF) 及其后继的 post-HF 方法，因其在处理多电子系统时展现出计算效率与精度的卓越平衡而占据核心地位。这些方法的理论基础深深植根于 二次量子化 的表述。二次量子化作为标准量子力学在多体问题中的一种优雅而强大的语言，通过引入 产生算符 \\(a_p^\\dagger\\) 和 湮灭算符 \\(a_p\\)，能够灵活地构造 Fock 空间 中的任意算符，例如哈密顿量和波函数。这种框架不仅精简了复杂量子系统的数学描述，更关键的是，它通过算符之间的 反对易关系，自动确保了电子作为费米子所要求的波函数反对称性。这一特性在计算化学中至关重要，是行列式驱动方法能够高效实现的关键。\nSlater 行列式的构造与反对称性 # 考虑一个由 \\(N\\) 个电子组成的分子系统，其电子结构在一组 \\(M\\) 个正交 自旋轨道 \\({\\phi_p(\\mathbf{x})}_{p=1}^M\\) 下描述，其中 \\(\\mathbf{x} = (\\mathbf{r}, \\sigma)\\) 表示电子的空间坐标 \\(\\mathbf{r}\\) 和自旋 \\(\\sigma\\)。这些自旋轨道被视为单粒子基函数，其具体形式在此不作深入讨论。根据 泡利不相容原理，多电子波函数必须在交换任意两个电子坐标时表现出反对称性。在 一次量子化 中，这一性质通过 反对称化算符 \\(\\hat{A}\\) 实现：\n$$ \\hat{A} = \\frac{1}{\\sqrt{N!}} \\sum_{P \\in S_N} \\epsilon(P) P, $$\n其中 \\(S_N\\) 是 \\(N\\) 阶置换群，\\(P\\) 为置换操作，\\(\\epsilon(P)\\) 表示置换的奇偶性（+1 为偶置换，-1 为奇置换）。将 \\(\\hat{A}\\) 作用于 \\(N\\) 个自旋轨道的简单乘积态（即 Hartree 积）：\n$$ \\Phi_{\\text{Hartree}} = \\phi_{p_1}(\\mathbf{x}_1) \\phi_{p_2}(\\mathbf{x}_2) \\cdots \\phi_{p_N}(\\mathbf{x}_N), $$\n即可得到归一化的 Slater 行列式：\n$$ \\Phi_{p_1 p_2 \\cdots p_N}(\\mathbf{x}_1, \\dots, \\mathbf{x}_N) = |\\phi_{p_1} \\phi_{p_2} \\cdots \\phi_{p_N}| = \\frac{1}{\\sqrt{N!}} \\begin{vmatrix} \\phi_{p_1}(\\mathbf{x}_1) \u0026amp; \\phi_{p_2}(\\mathbf{x}_1) \u0026amp; \\cdots \u0026amp; \\phi_{p_N}(\\mathbf{x}_1) \\\\ \\phi_{p_1}(\\mathbf{x}_2) \u0026amp; \\phi_{p_2}(\\mathbf{x}_2) \u0026amp; \\cdots \u0026amp; \\phi_{p_N}(\\mathbf{x}_2) \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ \\phi_{p_1}(\\mathbf{x}_N) \u0026amp; \\phi_{p_2}(\\mathbf{x}_N) \u0026amp; \\cdots \u0026amp; \\phi_{p_N}(\\mathbf{x}_N) \\\\ \\end{vmatrix}. $$\nSlater 行列式的代数结构天然满足反对称性：交换任意两个电子坐标 \\(\\mathbf{x}_i\\) 和 \\(\\mathbf{x}_j\\)，波函数变号：\n$$ \\Phi(\\cdots, \\mathbf{x}_i, \\cdots, \\mathbf{x}_j, \\cdots) = -\\Phi(\\cdots, \\mathbf{x}_j, \\cdots, \\mathbf{x}_i, \\cdots), $$\n这与行列式交换两行引入负号的性质一致。\n从数学视角看，Slater 行列式是 \\(N\\) 个自旋轨道在 外代数（Exterior Algebra） 中的 楔积（Wedge Product） 在特定坐标表象下的实现：\n$$ \\phi_{p_1} \\wedge \\phi_{p_2} \\wedge \\cdots \\wedge \\phi_{p_N} = \\frac{1}{\\sqrt{N!}} \\sum_{P \\in S_N} \\epsilon(P) \\phi_{P(p_1)} \\otimes \\phi_{P(p_2)} \\otimes \\cdots \\otimes \\phi_{P(p_N)}. $$\n楔积是构造反对称张量的普适方法，而 Slater 行列式则是其在电子坐标空间中的矩阵表达。在量子化学中，“行列式”、“反对称积”和“Slater 行列式”常互换使用，但需明确行列式是这一概念在特定基函数下的具体形式。\n二次量子化与 Fock 空间 # 二次量子化 将反对称性的处理提升至更高的抽象层次，并融入 Fock 空间 的代数结构。Fock 空间是由所有可能粒子数（包括真空态）的反对称态张成的希尔伯特空间。对于 \\(N\\) 电子系统，其状态空间是 Fock 空间的一个子空间。该空间的基矢（即 Slater 行列式）可通过 占据数（Occupation Number, ON）向量 \\((n_1, n_2, \\ldots, n_M)\\) 唯一标识，其中 \\(n_p = 1\\) 表示自旋轨道 \\(\\phi_p\\) 被占据，\\(n_p = 0\\) 表示空轨道，且 \\(\\sum_p n_p = N\\)。例如，Slater 行列式 \\(|\\phi_{p_1} \\cdots \\phi_{p_N}|\\) 对应 ON 态 \\(|n_1, \\ldots, n_M\\rangle\\)，其中仅当 \\(p \\in {p_1, \\ldots, p_N}\\) 时 \\(n_p = 1\\)，其余为 0。这种表示将多电子波函数从依赖 \\(N\\) 个显式坐标的函数简化为离散轨道占据信息的抽象态矢量，大幅简化了表示和运算。\n尽管一次量子化中的 Slater 行列式（坐标空间函数）与二次量子化中的 ON 态（Fock 空间基矢）形式不同，它们描述的是同一个 \\(N\\) 电子反对称量子态，具有等价的物理意义。在量子化学中，这两种表述（以及通过产生算符作用于真空态生成的 Fock 态）常交替使用，具体取决于上下文。\n反对称性的算符代数实现 # 在二次量子化中，费米子的反对称性由 产生算符 \\(a_p^\\dagger\\) 和湮灭算符 \\(a_p\\) 的反对易关系 保证：\n$$ { a_p, a_q^\\dagger } = a_p a_q^\\dagger + a_q^\\dagger a_p = \\delta_{pq}, $$\n$$ { a_p, a_q } = a_p a_q + a_q a_p = 0, $$\n$$ { a_p^\\dagger, a_q^\\dagger } = a_p^\\dagger a_q^\\dagger + a_q^\\dagger a_p^\\dagger = 0. $$\n其中，\\(a_p^\\dagger\\) 在真空态 \\(|\\text{vac}\\rangle\\) 上产生一个占据 \\(\\phi_p\\) 的电子，\\(a_p\\) 则湮灭之。任意 \\(N\\) 电子 Slater 行列式可表示为：\n$$ | \\Phi_{p_1 p_2 \\cdots p_N} \\rangle = a_{p_1}^\\dagger a_{p_2}^\\dagger \\cdots a_{p_N}^\\dagger | \\text{vac} \\rangle. $$\n由于 \\({a_p^\\dagger, a_q^\\dagger} = 0\\)，即 \\(a_p^\\dagger a_q^\\dagger = -a_q^\\dagger a_p^\\dagger\\)，交换两个产生算符引入负号：\n$$ \\cdots a_{p_j}^\\dagger \\cdots a_{p_i}^\\dagger \\cdots | \\text{vac} \\rangle = - \\cdots a_{p_i}^\\dagger \\cdots a_{p_j}^\\dagger \\cdots | \\text{vac} \\rangle, $$\n这与 Slater 行列式交换行列的性质一致。此外，\\(a_p^\\dagger a_p^\\dagger = 0\\) 直接反映了泡利原理——同一自旋轨道不可重复占据。因此，二次量子化通过算符代数隐式保证反对称性，无需显式构造行列式。\nSlater行列式（ON向量）的计算机存储 # 我们前面提到，Slater行列式和 ON 向量在Fock空间表述下的量子化学中是物理等价的两个概念。在接下来的内容中，我们将混合使用这两个名词。\n在Fock空间中，单个Slater行列式可以简洁地表示为一个长度为 \\(N_{SO}\\) 的向量，其中 \\(N_{SO}\\) 代表自旋轨道的总数。向量的每个元素取值为0（未占据）或1（占据）。例如，\\( |1,1,0,0,0,0\\rangle \\) 表示一个包含6个自旋轨道的体系，其中前两个自旋轨道被电子占据。然而，在计算机中高效存储和操作这些行列式时，直接使用这种显式向量形式并不理想，通常会采用更紧凑且运算效率更高的**位串（bitstring）**编码方式。\n位串编码（Bitstring Encoding） # 位串编码的基本思想是将每个自旋轨道映射为一个二进制位：自旋轨道被电子占据时对应位为1，未被占据时为0。这种表示方法不仅直观，还能显著节省存储空间。考虑到电子的自旋特性，为了便于计算（如处理自旋守恒的激发或应用自旋相关的算符），通常将自旋向上（\\(\\alpha\\), \\(\\uparrow\\)）和自旋向下（\\(\\beta\\), \\(\\downarrow\\)）的轨道占据情况分别存储在两个独立的位串中，即 alpha 和 beta。因此，一个完整的Slater行列式在计算机中通常由这一对位串来表示。\n在量子化学中，首先需要定义一套包含 \\(N_{mo}\\) 个空间轨道的基组 \\(\\{\\phi_k\\}_{k=1}^{N_{mo}}\\)。每个空间轨道 \\(\\phi_k\\) 可与 \\(\\alpha\\) 自旋函数结合形成 \\(\\alpha\\) 自旋轨道 \\(\\psi_{k\\alpha}\\)，或与 \\(\\beta\\) 自旋函数结合形成 \\(\\beta\\) 自旋轨道 \\(\\psi_{k\\beta}\\)。由此，\\(\\alpha\\) 和 \\(\\beta\\) 自旋轨道的数量均等于空间轨道数 \\(N_{mo}\\)。在限制性（Restricted）轨道表述中，第 \\(k\\) 个 \\(\\alpha\\) 自旋轨道和第 \\(k\\) 个 \\(\\beta\\) 自旋轨道共享相同的空间函数 \\(\\phi_k\\)。因此，alpha 位串的第 \\(j\\) 位和 beta 位串的第 \\(j\\) 位分别表示第 \\(j+1\\) 个空间轨道的 \\(\\alpha\\) 和 \\(\\beta\\) 自旋的占据情况。\n在非限制性（unrestricted）方法中，\\(\\alpha\\) 和 \\(\\beta\\) 电子可拥有不同的空间轨道，但位串编码的基本原理不变。而在广义（generalized）方法中，自旋轨道是 \\(\\alpha\\) 和 \\(\\beta\\) 自旋函数的线性组合，需采用不同的编码方式。 现代计算机体系结构对固定长度整数类型（如64位无符号整数 uint64_t）的处理尤为高效。因此，当 \\(N_{mo} \\leq 64\\) 时，alpha 和 beta 各可用一个 uint64_t 变量存储。我们可以定义一个简单的结构体来表示行列式的占据情况：\nstruct Determinant { uint64_t alpha; // Alpha自旋轨道占据情况 uint64_t beta; // Beta自旋轨道占据情况 }; 若 \\(N_{mo} \u0026gt; 64\\)，则需使用 uint64_t 数组（如 std::vector\u0026lt;uint64_t\u0026gt;）存储每个位串。例如，对于100个空间轨道，需 \\(\\lceil 100/64 \\rceil = 2\\) 个 uint64_t 整数来分别存储 alpha 和 beta。不过，对于许多中小型体系，64位整数已足够。\n相位因子（Phase Factor）与规范序（Canonical Ordering） # 仅靠轨道占据信息（即位串）无法完全定义一个Slater行列式。由于电子是费米子，交换任意两个电子（即交换产生式算符的顺序）会导致行列式符号反转：\\(a_i^\\dagger a_j^\\dagger = -a_j^\\dagger a_i^\\dagger\\)。因此，产生式算符的排列顺序对行列式的相位因子（通常为+1或-1）至关重要。\n为确保行列式表示的唯一性并正确处理相位，必须采用一个规范序。常见的约定包括：\nAlpha自旋块优先：所有 \\(\\alpha\\) 电子的产生式算符 \\(a_{i\\uparrow}^\\dagger\\) 排列在所有 \\(\\beta\\) 电子的产生式算符 \\(a_{j\\downarrow}^\\dagger\\) 之前。 块内轨道指数升序：在 \\(\\alpha\\) 和 \\(\\beta\\) 自旋块内部，产生式算符按轨道指数 \\(i\\) 或 \\(j\\) 的升序排列。 例如，对于行列式 \\(|J\\rangle = a_{k\\uparrow}^\\dagger a_{i\\uparrow}^\\dagger a_{j\\downarrow}^\\dagger |\\text{vac}\\rangle\\)（其中 \\(i \u0026lt; k\\)），根据规范序应重排为 \\(a_{i\\uparrow}^\\dagger a_{k\\uparrow}^\\dagger a_{j\\downarrow}^\\dagger |\\text{vac}\\rangle\\)。若从原始形式到规范序需奇数次对换，则 \\(|J\\rangle = - |I_{\\text{canonical}}\\rangle\\)。\n在实际计算中，通常以一个已知参考行列式（如Hartree-Fock行列式，相位定义为+1）为起点，通过激发操作生成新行列式。新行列式相对于参考态的相位需精确计算并存储，通常用0（+1）或1（-1）表示。可定义如下结构体：\nstruct DeterminantPhase { uint64_t alpha; uint64_t beta; uint8_t phase; // 0 = +1相位, 1 = -1相位 }; phase 成员存储行列式 \\((\\text{alpha}, \\text{beta})\\) 相对于全局参考态（通常为HF态）的相位，具体计算方法常在辅助函数中实现。\n存储与管理的优势 # 使用 alpha 和 beta 位串对并结合相位因子的存储方式具有以下优势：\n存储紧凑：对于 \\(N_{mo} \\leq 64\\) 的体系，每个行列式的轨道占据信息仅需两个 uint64_t 和一个字节（存储相位），比稀疏矩阵或字符串列表更高效。 快速比较与查找：Determinant 结构体便于实现判等（operator==）和排序（operator\u0026lt;），适用于标准库的有序容器（如 std::set, std::map）或无序容器（如 std::unordered_set, std::unordered_map）。 高效位运算： 电子数统计：通过 __builtin_popcountll 或 std::popcount（C++20） 快速计算位串中1的个数，即 \\(\\alpha\\) 或 \\(\\beta\\) 电子数。 激发操作：单激发、双激发等可通过位运算（如异或 ^、与 \u0026amp;、或 |）高效实现。例如，从轨道 \\(i\\) 到 \\(p\\) 的电子移动可通过 flip_bit(i) 和 flip_bit(p) 操作完成。 差异识别：两个行列式间的差异（激发类型）可通过位串异或操作快速确定。 综上，将Slater行列式表示为 alpha 和 beta 位串对，并显式存储其相对于规范序参考态的相位因子，是计算量子化学中兼顾存储与运算效率的成熟方案。\n","date":"2025-03-17","externalUrl":null,"permalink":"/zh-cn/docs/determinant-based-quantum-chemistrya-programming-practice/1/","section":"Docs","summary":"\u003ch2 class=\"relative group\"\u003e概述 \n    \u003cdiv id=\"%E6%A6%82%E8%BF%B0\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E6%A6%82%E8%BF%B0\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e  在现代量子化学中，行列式驱动的方法，如 \u003cstrong\u003eHartree-Fock (HF)\u003c/strong\u003e 及其后继的 \u003cstrong\u003epost-HF 方法\u003c/strong\u003e，因其在处理多电子系统时展现出计算效率与精度的卓越平衡而占据核心地位。这些方法的理论基础深深植根于 \u003cstrong\u003e二次量子化\u003c/strong\u003e 的表述。二次量子化作为标准量子力学在多体问题中的一种优雅而强大的语言，通过引入 \u003cstrong\u003e产生算符\u003c/strong\u003e \\(a_p^\\dagger\\) 和 \u003cstrong\u003e湮灭算符\u003c/strong\u003e \\(a_p\\)，能够灵活地构造 \u003cstrong\u003eFock 空间\u003c/strong\u003e 中的任意算符，例如哈密顿量和波函数。这种框架不仅精简了复杂量子系统的数学描述，更关键的是，它通过算符之间的 \u003cstrong\u003e反对易关系\u003c/strong\u003e，自动确保了电子作为费米子所要求的波函数反对称性。这一特性在计算化学中至关重要，是行列式驱动方法能够高效实现的关键。\u003c/p\u003e","title":"行列式驱动量子化学方法的编程实践（一）","type":"docs"},{"content":"","date":"2025-03-15","externalUrl":null,"permalink":"/zh-cn/tags/regular-expression/","section":"Tags","summary":"","title":"Regular Expression","type":"tags"},{"content":" 群的基本定义 # 一个群 (Group) 是由一个非空集合 \\(G\\) 与其上的二元运算（记为\\(\\circ\\)）构成的代数结构，该二元运算满足以下公理：\n结合律（Associativity）：\\(\\forall a, b, c \\in G\\)，有 \\((a \\circ b) \\circ c = a \\circ (b \\circ c).\\)\n单位元（Identity element）：存在一个元素 \\(e \\in G\\)，使得对任意 \\(a \\in G\\)：\\(e \\circ a = a \\circ e = a.\\)\n逆元（Inverse element）：对任意 \\(a \\in G\\)，存在一个元素 \\(a^{-1} \\in G\\)，满足 \\(a \\circ a^{-1} = a^{-1} \\circ a = e.\\)\n按照以上定义，群中的元素在运算 \\(\\circ\\) 下具有封闭性。\n需要注意的是，集合以及其上定义的群通常会共用一个符号 \\(G\\)，但它们是两个不同的数学对象。群上定义了超出集合概念的运算结构，更正式的情况下记为 \\((G, \\circ)\\)。我们称该集合为群\\(G\\)的基础集（underlying set）。\n最常见的两种二元运算为加法和乘法，而群上仅定义有一种运算，据此可以分出加法群（additive group）和乘法群（multiplicative group）。加法群的单位元即为0，任一元素 \\(x\\) 的逆元为 \\(-x\\)；乘法群的单位元为1，任一元素 \\(x\\) 的逆元为 \\(x^{-1}\\)。此外，排列复合、矩阵乘法、对称差、异或 XOR、函数复合等运算都能构成群。\n群的定义并不要求运算满足交换律，据此可以分出阿贝尔群（Abelian group）和非阿贝尔群（non-Abelian group）。群的阶（order）定义为群中元素的个数，记为 \\(|G|\\)。阶为有限的群称为有限群，阶为无穷的群称为无限群。\n基本概念 # 在研究集合时，我们会用到子集，函数和等价关系商等概念。类似的，在研究群时，我们会用到子群，同态和商群等概念。下面分别做介绍。\n子群 # 如果 \\(H\\) 是 \\(G\\) 的一个非空子集，并且 \\(H\\) 在 \\(G\\) 的运算 \\(\\circ\\) 下也构成一个群，那么\\(H\\)称为\\(G\\)的子群（Subgroup）。记作\\(H \\leq G\\)。子群的条件可以简化为以下判定法则：\n封闭性：\\(\\forall a, b \\in H\\)，有 \\(a \\circ b \\in H\\)。 单位元：群 \\(G\\) 的单位元 \\(e\\) 在 \\(H\\) 中。 逆元：\\(\\forall a \\in H\\)，其逆元 \\(a^{-1} \\in H\\)。 若 \\(H \\neq G\\) 且 \\(H \\leq G\\)，则称 \\(H\\) 为 \\(G\\) 的真子群（Proper subgroup），记作 \\(H \u0026lt; G\\)。\n陪集 # 设 \\(H\\) 是群 \\(G\\) 的一个子群，则可以使用 \\(H\\) 将 \\(G\\) 中的元素划分为若干个不相交且彼此具有相同大小的子集，这些子集称为 \\(H\\) 的陪集（coset）。陪集又可以分出左陪集和右陪集，给定 \\(G\\) 的一个元素 \\(g\\)，则有：\n左陪集（Left coset）：\\(gH = {g \\circ h \\mid h \\in H}\\) 右陪集（Right coset）：\\(Hg = {h \\circ g \\mid h \\in H}\\) 容易看出，\\(H\\) 的陪集的阶数与\\(H\\)的阶数相等，\\(H\\) 同时是自身的左陪集和右陪集。左陪集和右陪集的数量相等，称为 \\(H\\) 在 \\(G\\) 中的指数（index），记作 \\([G:H]\\)。\n一个重要的定理是拉格朗日定理：如果 \\(H\\) 是 \\(G\\) 的子群，那么 \\(|G|=|H|[G:H]\\)。这个定理描述了一个群和它的子群的阶数之间的关系。特别地，如果 \\(G\\) 是有限群，那么可以得到推论：只有整除 \\(|G|\\) 的数才可能是子群的阶，因此素数阶群必为循环群； \\(G\\) 中每个元素的阶都会整除群 \\(G\\) 的阶。\n正规子群 # \\(G\\)的所有元素\\(g\\)对应的左陪集和右陪集相等，即\\(gH=Hg\\)时，\\(H\\) 是 \\(G\\) 的正规子群（normal subgroup），记作 \\(H \\triangleleft G\\)。一个等价的定义是，一个正规子群 \\(H\\) 在其所属群 \\(G\\) 的元素 \\(g\\) 的共轭作用下保持不变，即 \\(gHg^{-1} = H\\)。\n商群 # 可以在陪集构成的集合上赋予一个满足群公理的运算，使之成为商群（quotient group）。正式地，若 \\(H\\) 是群 \\(G\\) 的一个正规子群，则可以在 \\(G\\) 的所有左陪集（或右陪集）集合上定义运算 \\((aH) \\circ (bH) = (a \\circ b)H\\)，这样构造出的代数结构称为商群，记作 \\(G/H\\)。\n事实上，能够证明如果这种商群结构能定义成功，则 \\(H\\) 必定是正规子群。左右陪集不等的情况下无法定义出满足群公理的二元运算，但仍可定义类似的结构，形成一个齐性空间。\n之所以称为“商”群，是因为类似于整数除法，8除以2等于4相当于我们把8个对象分组为了各含4个对象的两个子集。而商群类似于我们使用 \\(H\\) 对 \\(G\\)进行了划分。\n中心化子和正规化子 # 在群论中，中心化子和正规化子是两个重要的子群，它们分别描述了群中元素与特定元素或子集的可交换性，以及元素在共轭作用下对子群的影响。\n给定群 \\(G\\) 的一个元素 \\(a\\)，其中心化子（Centralizer） \\(C_G(a)\\) 是 \\(G\\) 中所有与 \\(a\\) 可交换的元素组成的集合： $$ C_{G}(a) = \\{g \\in G \\ | \\ ga = ag\\} $$ \\(C_G(a)\\) 是 \\(G\\) 的一个子群。\n更一般地，对于 \\(G\\) 的一个子集 \\(S\\)（不一定是子群），其中心化子 \\(C_G(S)\\) 是 \\(G\\) 中所有与 \\(S\\) 中每个一个元素都可交换的元素组成的集合： $$ C_G(S) = \\{g \\in G \\ | \\ gs = sg \\ \\forall s \\in S\\} = \\bigcap_{s \\in S} C_G(s) $$ \\(C_G(S)\\) 也是 \\(G\\) 的一个子群。\n群 \\(G\\) 的中心（Center） \\(Z(G)\\) 是 \\(G\\) 中所有与 \\(G\\) 中任意元素都可交换的元素组成的集合，即 \\(Z(G) = C_{G} (G)\\)： $$ Z(G) = \\{z \\in G \\ | \\ zg = gz \\ \\forall g \\in G\\} $$ 中心 \\(Z(G)\\) 是 \\(G\\) 的一个阿贝尔正规子群。\n给定群 \\(G\\) 的一个子群 \\(H\\)，其正规化子 (Normalizer) \\(N_{G}(H)\\) 是 \\(G\\) 中所有满足 \\(g H g^{-1} = H\\) 的元素 \\(g\\) 组成的集合： $$ N_{G}(H) = \\{g \\in G \\ | \\ g H g^{-1} = H\\} $$ 其中 \\(g H g^{-1} = \\{ghg^{-1} \\ | \\ h \\in H\\}\\)。\\(N_{G}(H)\\) 是 \\(G\\) 的一个子群。\n以下是关于正规化子的一些重要性质：\n子群 \\(H\\) 总是其自身正规化子 \\(N_G(H)\\) 的一个正规子群，即 \\(H \\triangleleft N_G(H)\\)。 \\(N_G(H)\\) 是 \\(G\\) 中包含 \\(H\\) 作为正规子群的最大的子群。 一个子群 \\(H\\) 是 \\(G\\) 的正规子群当且仅当 \\(N_G(H) = G\\)。 中心化子与正规化子的关系：对于群 \\(G\\) 的一个子群 \\(H\\)：\n\\(C_G(H)\\) 的元素 \\(g\\) 必须与 \\(H\\) 中的每个元素 \\(h\\) 可交换，即 \\(gh=hg\\)。 \\(N_G(H)\\) 的元素 \\(g\\) 只需要满足共轭作用 \\(gHg^{-1}\\) 保持 \\(H\\) 整体不变，即 \\(gH = Hg\\) （这与陪集的定义相关，也等价于 \\(gHg^{-1} = H\\)）。 显然，如果一个元素 \\(g\\) 与 \\(H\\) 中的每个元素都可交换，那么它必然满足 \\(gHg^{-1} = H\\)。因此，总是有 \\(C_G(H) \\leq N_G(H)\\)。 同时，\\(H\\) 自身也总是其正规化子 \\(N_G(H)\\) 的子群，即 \\(H \\leq N_G(H)\\) （因为对任意 \\(h\u0026rsquo; \\in H\\)，\\(h\u0026rsquo;H(h\u0026rsquo;)^{-1} = H\\) 由于 \\(H\\) 是子群）。 同态与同构 # 设 \\(G\\) 和 \\(H\\) 是两个群, 如果 \\(G\\) 到 \\(H\\) 有一个映射 \\(\\phi\\), 使得 $$ \\phi(ab) = \\phi(a) \\phi(b), \\forall a,b \\in G $$ 那么称 \\(\\phi\\) 是 \\(G\\) 到 \\(H\\) 的一个同态映射，简称为同态。\n如果 \\(\\phi\\) 是单射，则 \\(\\phi\\) 称为单同态；\n如果 \\(\\phi\\) 是满射，则 \\(\\phi\\) 称为满同态；\n如果 \\(\\phi\\) 是双射，则 \\(\\phi\\) 称为同构。此时我们说群 \\(G\\) 和 \\(H\\) 是同构的，记作 \\(G \\cong H\\)。\n显然同态保持群的运算结构，它具有以下基本性质：\n单位元映射到单位元：\\(\\phi(e_G) = e_H\\) 逆元映射到逆元：\\(\\phi(a^{-1}) = \\phi(a)^{-1}\\) 在研究同态时，两个重要概念是：\n核：同态 \\(\\phi: G \\rightarrow H\\) 的核定义为映射到 \\(H\\) 单位元的 \\(G\\) 中所有元素构成的集合： $$ \\ker(\\phi) = {g \\in G \\mid \\phi(g) = e_H} $$\n像：同态 \\(\\phi\\) 的像是 \\(G\\) 中所有元素通过 \\(\\phi\\) 映射得到的 \\(H\\) 的子集： $$ \\text{im}(\\phi) = {\\phi(g) \\mid g \\in G} $$\n可以证明，同态的核是原群的正规子群，而同态的像是目标群的子群。\n第一同构定理：如果 \\(\\phi: G \\rightarrow H\\) 是群同态，则 $$G/\\ker(\\phi) \\cong \\text{im}(\\phi)$$\n这里的概念可能有些复杂，我们举三个例子进行说明：\n1. 从整数群 \\(\\mathbb{Z}\\) 到整数模 \\(n\\) 群 \\(\\mathbb{Z}_n\\) 的映射\n我们构造一个映射： $$ \\phi: \\mathbb{Z} \\rightarrow \\mathbb{Z}_n, \\quad \\phi(k) = k \\operatorname{mod} n $$\n可以快速对该映射的同态性质进行检验，\\(\\forall a,b \\in \\mathbb{Z}\\)， $$ \\phi(a+b) = (a+b) \\operatorname{mod} n $$ $$ \\phi(a) \\oplus \\phi(b) = [(a \\operatorname{mod} n) + (b \\operatorname{mod} n)] \\operatorname{mod} n = (a+b) \\operatorname{mod} n $$ 其中第二个式子利用了模运算的基本性质。可见该映射确实构成了一个群同态。\n我们现在将目光转移到该同态的核与像，显然我们有： $$ \\ker(\\phi) = \\{k \\in \\mathbb{Z} \\,|\\, \\phi(k)=0 \\in \\mathbb{Z}_n \\} = \\{k \\in \\mathbb{Z} \\,|\\, k \\operatorname{mod} n =0 \\} = n\\mathbb{Z} $$ 核由所有能被 \\(n\\) 整除的整数构成，这些元素在映射后都变成 \\(\\mathbb{Z}_n\\) 的单位元“0”。也就是说，这些元素在映射后不可区分。而 $$ \\operatorname{Im}(\\phi) = \\{\\phi(k): k \\in \\mathbb{Z}\\} = \\mathbb{Z}_n $$ 显然这个映射是满射。\n由于 \\(\\phi\\) 是满射，但不是单射，因此它不是一个同构。\n根据第一同构定理， $$ G / \\ker(\\phi) \\cong \\operatorname{Im}(\\phi) \\Longrightarrow \\mathbb{Z} / n \\mathbb{Z} \\cong \\mathbb{Z}_n $$ 也就是说，当我们把 \\(\\mathbb{Z}\\) 按照子群 \\(n\\mathbb{Z}\\) 进行划分后，得到的商群与 \\(\\mathbb{Z}_n\\) 同构。\n2. 从正实数乘法群 \\(\\mathbb{R}^{*}_{+}\\) 到实数加法群 \\(\\mathbb{R}\\) 的对数映射\n我们定义映射： $$ \\phi: \\mathbb{R}^{*}_{+} \\Longrightarrow \\mathbb{R} \\quad \\phi(x) = \\ln(x) $$ 显然我们有： $$ \\phi(x \\times y) = \\ln(xy) = \\ln(x) + \\ln(y) = \\phi(x) + \\phi(y) $$\n因此该映射是一个同态\n$$ \\ker(\\phi) = \\{x \\in \\mathbb{R}^{*}_{+} | \\ln(x) = 0 \\} = \\{ 1 \\} $$\n只有 \\(\\mathbb{R}^{*}_{+}\\) 的单位元1被映射到目标群 \\(\\mathbb{R}\\) 的单位元0。因此 \\(\\phi\\) 是一个单射。\n$$ \\operatorname{Im}(\\phi) = \\{\\ln(x): x \u0026gt; 0\\} = \\mathbb{R} $$\n这也是一个满射。\n因此该映射是一个同构，直观理解就是，乘法对应加法是指数与对数的互逆关系。\n3. 从可逆矩阵群 \\(\\mathrm{GL}_n(\\mathbb{R})\\) 到非零实数乘法群 \\(\\mathbb{R}^*\\) 的行列式映射\n这里 \\(\\mathrm{GL}_n(\\mathbb{R})\\) 是所有 \\(n \\times n\\) 可逆实矩阵的集合，运算是“矩阵乘法”。\n构造映射：\n$$ \\mathrm{GL}_n(\\mathbb{R}) \\rightarrow \\mathbb{R}^* \\quad A \\mapsto \\det(A) $$\n显然对于任意可逆矩阵 \\(A, B\\)，我们有：\n$$ \\det(A B) = \\det(A) \\cdot \\det(B) $$\n因此该映射是一个同态。\n对于核与像，我们有：\n$$ \\ker(\\det) = \\{A \\in \\mathrm{GL}_n(\\mathbb{R}) \\,|\\, \\det(A)=1 \\} $$\n核是所有行列式为1的可逆矩阵构成的集合，通常记为 \\(\\mathrm{SL}_n(\\mathbb{R})\\)。显然该映射不是单射。\n$$ \\operatorname{Im}(\\det) = \\{\\det(A): A \\in \\mathrm{GL}_n(\\mathbb{R})\\} = \\mathbb{R}^* $$\n这是因为给定任意 \\(r \\ne 0\\)，都能找到一个对角矩阵 \\(\\operatorname{diag}(r, 1, 1, \\ldots, 1)\\)，使其行列式值为 \\(r\\)。因此该映射是满射。\n因此该同态不是同构，这体现了尽管行列式把矩阵映射的较为简明，但同一个行列式值的不同矩阵在目标群中被压缩为了同一个点。\n因此，核可以帮助我们发现“映射过程中被合并了哪些元素（信息）”；像可以帮助我们看出“同态覆盖了目标群的哪些部分”。一旦核只有单位元，就意味着没有任何元素被额外折叠，映射是单射。若此时像又是整个目标群，那么两个群就同构。\n示例 # 想象一张在平面上的正方形纸，所有能够将这张正方形纸映射到自身的几何变换（例如旋转、翻折）构成了一个群。我们用 \\(D_4\\) 表示它，常称为“正方形的二面体群”，其基础集中包含八个元素（八种刚体运动），运算则是“连续地做变换”（也就是复合）。为方便描述，我们把顺时针旋转 \\(90^\\circ\\) 记作 \\(r\\)，把绕固定对称轴的一次翻折记作 \\(s\\)。\\(D_4\\) 的八个元素可写为： $$ \\{\\, e,\\; r,\\; r^2,\\; r^3,\\; s,\\; rs,\\; r^2s,\\; r^3s \\}, $$ 其中 \\(e\\) 表示“不动”，即恒等变换；\\(r^k\\) 表示顺时针旋转 \\(90^\\circ\\) 的 \\(k\\) 次方；\\(s\\) 表示一次翻折；\\(r^k s\\) 表示先翻折、再旋转 \\(k\\) 次（或者先旋转 \\(k\\) 次，再翻折，视变换顺序约定而定，但概念上就是“旋转+翻折”的组合）。\n在 \\(D_4\\) 里，任何三个变换复合起来都可以通过结合律减少成两个变换的复合，不会有歧义；不动元 \\(e\\) 对任何元素都满足 \\(e \\circ g = g \\circ e = g\\)；每个变换都有“逆变换”，例如 \\(r\\) 的逆元是 \\(r^3\\)，翻折 \\(s\\) 的逆元就是它本身 \\(s\\)。所以 \\(D_4\\) 确实是一个群。\n再来看子群。\\(D_4\\) 里有一个重要子群，即只做旋转的那部分 \\(\\langle r\\rangle = \\{e,\\, r,\\, r^2,\\, r^3\\}\\)。它的元素个数是4，满足前面提到的三条子群判定标准，故 \\(\\langle r\\rangle\\) 的确是 \\(D_4\\) 的子群。作为子群，\\(\\langle r\\rangle\\) 在全群中的单位元还是同一个 \\(e\\)，逆元也沿用 \\(D_4\\) 的“逆变换”概念。\\(\\langle r\\rangle\\) 本身又是一个循环群。\n如果拿 \\(\\langle r\\rangle\\) 去划分陪集，可以将 \\(D_4\\) 的八个元素划分为两个大小相等的不相交子集：\\(\\langle r\\rangle\\) 自身（它既是一个左陪集，也是一个右陪集），以及 \\(s\\langle r\\rangle = \\{s,\\, rs,\\, r^2s,\\, r^3s\\}\\)。我们可以感受一下这一划分：任意元素若属于第一个子集（只做旋转），或第二个子集（带有翻折），彼此就不会有重叠，也恰好把群里的元素“一分为二”。这说明了指数 \\([D_4 : \\langle r\\rangle]\\) 是2，从而也能验证拉格朗日定理里的 \\(|D_4| = 8\\) 与 \\(|\\langle r\\rangle|=4\\) 的关系：\\(8 = 4 \\times 2\\)。\n继续观察会发现 \\(\\langle r\\rangle\\) 还是 \\(D_4\\) 的一个正规子群，即对每一个 \\(g \\in D_4\\)，都有 \\(g \\langle r\\rangle g^{-1} = \\langle r\\rangle\\)。直观来说，对称地“转一圈”再“转回来”，或者“翻折一下”再“翻回来”，都不会跳出那个纯粹旋转的子群。因为 \\(\\langle r\\rangle\\) 是正规子群，我们可以在它的陪集上赋予群运算，从而形成商群 \\(D_4 / \\langle r\\rangle\\)。这个商群只有两个元素：一个是 \\(\\langle r\\rangle\\) 自身，另一个是 \\(s \\langle r\\rangle\\)。运算定义如下：\\((a\\langle r\\rangle) \\circ (b\\langle r\\rangle) = (a \\circ b)\\langle r\\rangle\\)。读起来可能有点抽象，其实可以把这两个陪集理解成“是否带有翻折”的两种对称类型，整个结构恰好和只有两个元素的群（记为 \\(\\mathbb{Z}_2\\) 或者 \\({0,1}\\)）相似，也就是我们在抽象上把“纯旋转”和“带翻折”当作两个宏观的等价类。\n最后定义一个映射 \\(\\phi: D_4 \\to \\{1, -1\\}\\)（其中 \\(\\{1,-1\\}\\) 可以理解成一个两元素的乘法群），规定凡是“纯旋转”的元素都映射到 \\(1\\)，凡是“带翻折”的元素都映射到 \\(-1\\)。这样便保持了群结构：任何两个纯旋转复合仍是纯旋转，对应 \\(1 \\times 1 = 1\\)；任何翻折与旋转的组合出来还是翻折，对应 \\(1 \\times -1 = -1\\)；两个翻折复合回到纯旋转，对应 \\((-1) \\times (-1) = 1\\)。这映射 \\(\\phi\\) 就是一个群同态。它的核正是 \\(\\langle r\\rangle\\)，对应映到 \\(1\\) 的所有元素；它的像是 \\(\\{1, -1\\}\\)，即整个目标群。按照第一同构定理，我们得到 \\(D_4 / \\langle r\\rangle \\cong \\{1, -1\\}\\)，呼应了上面关于商群的认识。\n","date":"2025-03-15","externalUrl":null,"permalink":"/zh-cn/docs/summary-of-group-theory/group1/","section":"Docs","summary":"\u003ch2 class=\"relative group\"\u003e群的基本定义 \n    \u003cdiv id=\"%E7%BE%A4%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%AE%9A%E4%B9%89\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E7%BE%A4%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%AE%9A%E4%B9%89\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e  一个\u003cstrong\u003e群\u003c/strong\u003e (Group) 是由一个非空集合 \\(G\\) 与其上的二元运算（记为\\(\\circ\\)）构成的代数结构，该二元运算满足以下公理：\u003c/p\u003e","title":"群论：基本概念","type":"docs"},{"content":" RRKM Theory is a Microcanonical Version of TST # RRKM Theory (Rice–Ramsperger–Kassel–Marcus Theory) is indeed often considered a microcanonical extension of Transition State Theory (TST). Both theories share foundational assumptions and are used to describe reaction rates, but they operate within different statistical frameworks:\nTST typically operates within a canonical (constant temperature) ensemble, assuming that the system is in thermal equilibrium with a heat bath. RRKM Theory extends TST to a microcanonical (constant energy) ensemble, allowing for the calculation of unimolecular reaction rates as a function of energy. Common Assumptions in RRKM and TST # Born-Oppenheimer (BO) Approximation: Both theories assume the BO approximation, which separates electronic and nuclear motions due to the large difference in their masses. This allows the potential energy surface (PES) to be treated independently of electronic transitions during the reaction.\nEquilibrium Between Reactants and Activated Complex: Both theories assume that there is a rapid and reversible equilibrium between reactants and the activated (transition) complex. This implies that the population of the activated complex is determined by the equilibrium distribution.\nNo Recrossing of the Transition State: Both theories assume that once the system crosses the transition state, it proceeds to form products without reverting to reactants. This idealization means that the transmission coefficient (κ) is assumed to be close to 1, indicating minimal or no recrossing.\nSeparable Reaction Paths: The reaction path is assumed to be separable from the other degrees of freedom, allowing the reaction coordinate to be treated independently. This simplifies the analysis by focusing on the primary pathway of the reaction.\nLimitations # Given the assumptions outlined above, RRKM Theory and TST have several limitations that constrain their applicability:\nSingle Reaction Surface:\nLimitation: These theories are only applicable to reactions that proceed along a single, well-defined potential energy surface (PES) without significant contributions from multiple pathways or surfaces. Implication: Reactions involving multiple competing pathways or surface crossings cannot be accurately described using RRKM or TST. Long Transition State Lifetimes Relative to IVR:\nLimitation: Both theories require that the lifetime of the transition state is much longer than the timescale of Intramolecular Vibrational Redistribution (IVR). Implication: If IVR is not sufficiently rapid, the energy within the activated complex may not be uniformly redistributed, violating the statistical energy distribution assumption and leading to inaccurate rate predictions. Transmission Coefficient Near 1:\nLimitation: The assumption that the transmission coefficient (κ) is close to 1 implies negligible recrossing of the transition state. Implication: In systems where recrossing is significant, the transmission coefficient deviates from 1, rendering the theories\u0026rsquo; rate predictions unreliable. Inapplicability to Barrierless Reactions:\nLimitation: Both RRKM and TST rely on the existence of a well-defined transition state with an associated energy barrier. Implication: Barrierless reactions, which proceed without a significant energy barrier or distinct transition state, cannot be accurately described by these theories. Alternative models, such as direct dynamics simulations, are required for such reactions. Assumption of Separable Reaction Paths:\nLimitation: The assumption that the reaction coordinate is separable from other degrees of freedom may not hold in systems where there is strong coupling between the reaction coordinate and other vibrational modes. Implication: In such cases, the energy distribution cannot be treated independently, leading to potential inaccuracies in rate calculations. Neglect of Quantum Effects:\nLimitation: Both theories primarily treat nuclear motion classically and may not account for quantum mechanical effects such as tunneling, especially significant in reactions involving light atoms like hydrogen. Implication: For reactions where quantum effects play a crucial role, RRKM and TST may underestimate or misrepresent the actual reaction rates. Summary # RRKM Theory extends TST to a microcanonical framework, maintaining similar foundational assumptions. Both theories assume the Born-Oppenheimer approximation, equilibrium between reactants and the activated complex, no recrossing, and separable reaction paths. Limitations: Applicable only to single reaction surfaces. Require that the transition state lifetime is much longer than IVR. Assume the transmission coefficient is near 1. Not suitable for barrierless reactions. Depend on the separability of reaction paths and often neglect quantum effects. ","date":"25 October 2024","externalUrl":null,"permalink":"/docs/tst-and-rrkm-/test/","section":"Docs","summary":"\u003ch3 class=\"relative group\"\u003e\u003cstrong\u003eRRKM Theory is a Microcanonical Version of TST\u003c/strong\u003e \n    \u003cdiv id=\"rrkm-theory-is-a-microcanonical-version-of-tst\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#rrkm-theory-is-a-microcanonical-version-of-tst\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eRRKM Theory (Rice–Ramsperger–Kassel–Marcus Theory)\u003c/strong\u003e is indeed often considered a microcanonical extension of \u003cstrong\u003eTransition State Theory (TST)\u003c/strong\u003e. Both theories share foundational assumptions and are used to describe reaction rates, but they operate within different statistical frameworks:\u003c/p\u003e","title":"Assumptions and Limitations in RRKM and TST","type":"docs"},{"content":" 这篇文章也用于评估KaTeX的渲染性能。 原文为英文，该文本由自然语言处理程序翻译得到。 引言 # 考虑一个一般的基元反应： $$ a \\mathrm{A} + b \\mathrm{B} \\rightarrow c \\mathrm{C} + d \\mathrm{D} $$ 根据惯例，为了使反应从左到右进行时速率为正，我们对生成物选择正的导数，对反应物选择负的导数。微分速率方程可以写为： $$ \\frac{1}{c} \\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} = \\frac{1}{d} \\frac{\\mathrm{d}[\\mathrm{D}]}{\\mathrm{d}t} = -\\frac{1}{a} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -\\frac{1}{b} \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k [\\mathrm{A}]^{a} [\\mathrm{B}]^b $$ 反应的级数是速率方程中反应物的指数之和。总反应级数是每个反应物对应的反应级数之和。速率常数 \\(k\\) 与温度有关，但与反应物的浓度无关。\n最常见的基元反应是零级、一级和二级反应，而三级及以上的反应很少见。以下将推导这些反应的积分速率方程。\n零级反应 # 对于零级反应，速率方程为： $$ \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k $$ 对这个方程进行积分得到： $$ [\\mathrm{A}] = -kt + [\\mathrm{A}(0)] $$ 这个方程描述了反应物浓度随时间的变化。\n一级反应 # 对于一级反应，速率方程为： $$ \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -k[\\mathrm{A}] $$ 对这个方程进行积分得到： $$ \\ln [\\mathrm{A}] = -kt + \\ln [\\mathrm{A}(0)] $$ 这个方程描述了反应物浓度随时间的变化。\n二级反应 # \\(2 \\mathrm{A} \\rightarrow \\mathrm{products}\\) # 对于反应 \\(2 \\mathrm{A} \\rightarrow \\mathrm{products}\\)，微分速率方程为： $$ \\frac{1}{2} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = k[\\mathrm{A}]^2 $$ 设 \\(x\\) 表示反应的进度，即 \\(\\mathrm{A}\\) 的浓度变化。则有： $$ [\\mathrm{A}] = [\\mathrm{A}(0)] - 2x $$ 代入速率方程得到： $$ \\frac{\\mathrm{d}x}{\\mathrm{d}t} = k ([\\mathrm{A}(0)] - 2x)^2 $$ 分离变量： $$ \\int \\frac{\\mathrm{d}x}{([\\mathrm{A}(0)] - 2x)^2} = k \\int \\mathrm{d}t $$ 对两边积分： $$ -\\frac{1}{2[\\mathrm{A}]} + \\frac{1}{2[\\mathrm{A}(0)]} = kt $$ 重新整理： $$ \\frac{1}{[\\mathrm{A}]} = 2kt + \\frac{1}{[\\mathrm{A}(0)]} $$ 这个方程描述了反应物浓度随时间的变化。\n\\(\\mathrm{A} + \\mathrm{B} \\rightarrow \\mathrm{products}\\) # 对于反应 \\(\\mathrm{A} + \\mathrm{B} \\rightarrow \\mathrm{products}\\)，微分速率方程为： $$ -\\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -\\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k[\\mathrm{A}][\\mathrm{B}] $$ 设 \\(x\\) 表示反应的进度。则有： $$ [\\mathrm{A}] = [\\mathrm{A}(0)] - x, \\quad [\\mathrm{B}] = [\\mathrm{B}(0)] - x $$ 代入速率方程： $$ \\frac{\\mathrm{d}x}{\\mathrm{d}t} = k([\\mathrm{A}(0)] - x)([\\mathrm{B}(0)] - x) $$ 分离变量： $$ \\int \\frac{\\mathrm{d}x}{([\\mathrm{A}(0)] - x)([\\mathrm{B}(0)] - x)} = k \\int \\mathrm{d}t $$ 使用部分分数分解： $$ \\frac{1}{([\\mathrm{A}(0)] - x)([\\mathrm{B}(0)] - x)} = \\frac{1}{[\\mathrm{A}(0)] - [\\mathrm{B}(0)]} \\left(\\frac{1}{[\\mathrm{B}(0)] - x} - \\frac{1}{[\\mathrm{A}(0)] - x}\\right) $$ 对两边积分： $$ \\frac{1}{[\\mathrm{A}(0)] - [\\mathrm{B}(0)]} \\ln \\frac{[\\mathrm{A}][\\mathrm{B}(0)]}{[\\mathrm{A}(0)][\\mathrm{B}]} = kt $$ 这个方程描述了两个反应物的浓度随时间的变化。\n三级反应 # \\(\\text{A}+\\text{B}+\\text{C} \\rightarrow \\text{products}\\) # 对于含有三个不同反应物的三级反应，微分速率方程为： $$ -\\frac{d[\\text{A}]}{dt} = -\\frac{d[\\text{B}]}{dt} = -\\frac{d[\\text{C}]}{dt} = k[\\text{A}][\\text{B}][\\text{C}] $$\n设 \\(x\\) 表示反应的进度。则有： $$ [\\text{A}] = [\\text{A}(0)] - x, \\quad [\\text{B}] = [\\text{B}(0)] - x, \\quad [\\text{C}] = [\\text{C}(0)] - x $$\n代入速率方程： $$ \\frac{dx}{dt} = k([\\text{A}(0)] - x)([\\text{B}(0)] - x)([\\text{C}(0)] - x) $$\n分离变量：\n$$ \\int \\frac{dx}{([\\text{A}(0)] - x)([\\text{B}(0)] - x)([\\text{C}(0)] - x)} = k \\int dt $$\n使用部分分数分解：\n$$ \\frac{1}{([\\text{A}(0)] - x)([\\text{B}(0)] - x)([\\text{C}(0)] - x)} = \\frac{A}{[\\text{A}(0)] - x} + \\frac{B}{[\\text{B}(0)] - x} + \\frac{C}{[\\text{C}(0)] - x} $$\n两边乘以 \\(([\\text{A}(0)] - x)([\\text{B}(0)] - x)([\\text{C}(0)] - x)\\) 并展开，通过匹配各项确定系数 \\(A\\)、\\(B\\) 和 \\(C\\)。解得：\n$$ A = \\frac{1}{([\\text{B}(0)] - [\\text{A}(0)])([\\text{C}(0)] - [\\text{A}(0)])}, \\quad B = \\frac{1}{([\\text{A}(0)] - [\\text{B}(0)])([\\text{C}(0)] - [\\text{B}(0)])}, \\quad C = \\frac{1}{([\\text{A}(0)] - [\\text{C}(0)])([\\text{B}(0)] - [\\text{C}(0)])} $$\n因此，积分变为\n$$ A \\int \\frac{dx}{[\\text{A}(0)] - x} + B \\int \\frac{dx}{[\\text{B}(0)] - x} + C \\int \\frac{dx}{[\\text{C}(0)] - x} = kt + \\text{常数} $$\n对两边积分并合并常数，得到积分速率方程：\n$$ \\frac{1}{([\\text{B}(0)] - [\\text{A}(0)])([\\text{C}(0)] - [\\text{A}(0)])} \\ln\\left(\\frac{[\\text{B}][\\text{C}][\\text{A}(0)]}{[\\text{B}(0)][\\text{C}(0)][\\text{A}]}\\right) + \\frac{1}{([\\text{A}(0)] - [\\text{B}(0)])([\\text{C}(0)] - [\\text{B}(0)])} \\ln\\left(\\frac{[\\text{A}][\\text{C}][\\text{B}(0)]}{[\\text{A}(0)][\\text{C}(0)][\\text{B}]}\\right) + \\frac{1}{([\\text{A}(0)] - [\\text{C}(0)])([\\text{B}(0)] - [\\text{C}(0)])} \\ln\\left(\\frac{[\\text{A}][\\text{B}][\\text{C}(0)]}{[\\text{A}(0)][\\text{B}(0)][\\text{C}]}\\right) = kt $$\n\\(2 \\text{A} + \\text{B} \\rightarrow \\text{products}\\) # 从微分速率方程开始：\n$$ \\frac{1}{2} \\frac{d[\\text{A}]}{dt} = -\\frac{d[\\text{B}]}{dt} = k[\\text{A}]^2[\\text{B}] $$\n设 \\(x\\) 表示反应的进度，\\(x\\) 为 \\(\\text{B}\\) 的浓度变化。则有\n$$ [\\text{A}] = [\\text{A}(0)] - 2x, \\quad [\\text{B}] = [\\text{B}(0)] - x $$\n代入速率方程得到\n$$ \\frac{dx}{dt} = k ([\\text{A}(0)] - 2x)^2 ([\\text{B}(0)] - x) $$\n分离变量：\n$$ \\int \\frac{dx}{([\\text{A}(0)] - 2x)^2 ([\\text{B}(0)] - x)} = k \\int dt $$\n使用部分分数分解，\n$$ \\frac{1}{([\\text{A}(0)] - 2x)^2 ([\\text{B}(0)] - x)} = \\frac{A}{[\\text{A}(0)] - 2x} + \\frac{B}{([\\text{A}(0)] - 2x)^2} + \\frac{C}{[\\text{B}(0)] - x} $$\n两边乘以 \\(([\\text{A}(0)] - 2x)^2 ([\\text{B}(0)] - x)\\) 并展开，通过匹配各项确定系数 \\(A\\)、\\(B\\) 和 \\(C\\)。解得\n$$ A = -\\frac{2}{\\left( [\\text{A}(0)] - 2[\\text{B}(0)] \\right)^2}, \\quad B = -\\frac{2}{[\\text{A}(0)] - 2[\\text{B}(0)]}, \\quad C = \\frac{1}{\\left( [\\text{A}(0)] - 2[\\text{B}(0)] \\right)^2} $$\n因此，积分变为\n$$ \\int \\frac{dx}{([\\text{A}(0)] - 2x)^2 ([\\text{B}(0)] - x)} = -\\frac{1}{\\left( [\\text{A}(0)] - 2[\\text{B}(0)] \\right)} \\left( \\frac{1}{[\\text{A}]} - \\frac{1}{[\\text{A}(0)]} \\right) - \\frac{1}{\\left( [\\text{A}(0)] - 2[\\text{B}(0)] \\right)^2} \\ln \\frac{[\\text{A}][\\text{B}(0)]}{[\\text{A}(0)][\\text{B}]} $$\n对两边积分并合并常数，得到积分速率方程：\n$$ \\frac{1}{[\\text{A}(0)] - 2[\\text{B}(0)]} \\left( \\frac{1}{[\\text{A}(0)]} - \\frac{1}{[\\text{A}]} \\right) + \\frac{1}{\\left( [\\text{A}(0)] - 2[\\text{B}(0)] \\right)^2} \\ln \\frac{[\\text{A}][\\text{B}(0)]}{[\\text{A}(0)][\\text{B}]} = kt $$\n","date":"2024-10-25","externalUrl":null,"permalink":"/zh-cn/docs/differential-and-integral-rate-laws-for-common-types-of-reactions/test/","section":"Docs","summary":"\u003cdiv\n  \n    class=\"flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900\"\n  \u003e\n\n  \u003cspan\n    \n      class=\"text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center\"\n    \u003e\n\n    \n\n  \u003cspan class=\"relative block icon\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z\"/\u003e\u003c/svg\u003e\n\n  \u003c/span\u003e\n\n\n  \u003c/span\u003e\n\n  \u003cspan\n    \n      class=\"dark:text-neutral-300\"\n    \u003e这篇文章也用于评估KaTeX的渲染性能。\u003c/span\u003e\n\u003c/div\u003e\n\n\n  \n\n\n\n\u003cdiv\n  \n    class=\"flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900\"\n  \u003e\n\n  \u003cspan\n    \n      class=\"text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center\"\n    \u003e\n\n    \n\n  \u003cspan class=\"relative block icon\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z\"/\u003e\u003c/svg\u003e\n\n  \u003c/span\u003e\n\n\n  \u003c/span\u003e\n\n  \u003cspan\n    \n      class=\"dark:text-neutral-300\"\n    \u003e原文为英文，该文本由自然语言处理程序翻译得到。\u003c/span\u003e\n\u003c/div\u003e\n\n\n\n\u003ch2 class=\"relative group\"\u003e引言 \n    \u003cdiv id=\"%E5%BC%95%E8%A8%80\" class=\"anchor\"\u003e\u003c/div\u003e\n    \n    \u003cspan\n        class=\"absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\"\u003e\n        \u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\"\n            style=\"text-decoration-line: none !important;\" href=\"#%E5%BC%95%E8%A8%80\" aria-label=\"锚点\"\u003e#\u003c/a\u003e\n    \u003c/span\u003e        \n    \n\u003c/h2\u003e\n\u003cp\u003e考虑一个一般的基元反应：\n$$\na \\mathrm{A} + b \\mathrm{B} \\rightarrow c \\mathrm{C} + d \\mathrm{D}\n$$\n根据惯例，为了使反应从左到右进行时速率为正，我们对生成物选择正的导数，对反应物选择负的导数。微分速率方程可以写为：\n$$\n\\frac{1}{c} \\frac{\\mathrm{d}[\\mathrm{C}]}{\\mathrm{d}t} = \\frac{1}{d} \\frac{\\mathrm{d}[\\mathrm{D}]}{\\mathrm{d}t} = -\\frac{1}{a} \\frac{\\mathrm{d}[\\mathrm{A}]}{\\mathrm{d}t} = -\\frac{1}{b} \\frac{\\mathrm{d}[\\mathrm{B}]}{\\mathrm{d}t} = k [\\mathrm{A}]^{a} [\\mathrm{B}]^b\n$$\n反应的级数是速率方程中反应物的指数之和。总反应级数是每个反应物对应的反应级数之和。速率常数 \\(k\\) 与温度有关，但与反应物的浓度无关。\u003c/p\u003e","title":"常见反应类型的微分速率法则与积分速率法则","type":"docs"},{"content":"","externalUrl":null,"permalink":"/zh-cn/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/zh-cn/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"}]